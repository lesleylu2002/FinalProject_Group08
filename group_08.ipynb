{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f8ca24",
   "metadata": {},
   "source": [
    "# Understanding Hired Rides in NYC\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1VERPjEZcC1XSs4-02aM-DbkNr_yaJVbFjLJxaYQswqA/edit#)_\n",
    "\n",
    "_This scaffolding notebook may be used to help setup your final project. It's **totally optional** whether you make use of this or not._\n",
    "\n",
    "_If you do use this notebook, everything provided is optional as well - you may remove or add prose and code as you wish._\n",
    "\n",
    "_Anything in italics (prose) or comments (in code) is meant to provide you with guidance. **Remove the italic lines and provided comments** before submitting the project, if you choose to use this scaffolding. We don't need the guidance when grading._\n",
    "\n",
    "_**All code below should be consider \"pseudo-code\" - not functional by itself, and only a suggestion at the approach.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75fd94",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "66dcde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all import statements needed for the project, for example:\n",
    "\n",
    "import os\n",
    "\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import requests\n",
    "import sqlalchemy as db\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import fiona\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f1242c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any constants you might need; some have been added for you, and \n",
    "# some you need to fill in\n",
    "\n",
    "TLC_URL = \"https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "\n",
    "TAXI_ZONES_DIR = \"\"\n",
    "TAXI_ZONES_SHAPEFILE = f\"{TAXI_ZONES_DIR}/taxi_zones.shp\"\n",
    "WEATHER_CSV_DIR = \"\"\n",
    "\n",
    "CRS = 4326  # coordinate reference system\n",
    "\n",
    "# (lat, lon)\n",
    "NEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\n",
    "LGA_BOX_COORDS = ((40.763589, -73.891745), (40.778865, -73.854838))\n",
    "JFK_BOX_COORDS = ((40.639263, -73.795642), (40.651376, -73.766264))\n",
    "EWR_BOX_COORDS = ((40.686794, -74.194028), (40.699680, -74.165205))\n",
    "\n",
    "DATABASE_URL = \"sqlite:///project.db\"\n",
    "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "QUERY_DIRECTORY = \"queries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6601633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the QUERY_DIRECTORY exists\n",
    "try:\n",
    "    os.mkdir(QUERY_DIRECTORY)\n",
    "except Exception as e:\n",
    "    if e.errno == 17:\n",
    "        # the directory already exists\n",
    "        pass\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad10ea",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b98651bc-39b5-4da2-971d-3f09256a3285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-01.parquet ...\n",
      "File saved to: data/yellow_taxi/2020-01.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-02.parquet ...\n",
      "File saved to: data/yellow_taxi/2020-02.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-03.parquet ...\n",
      "File saved to: data/yellow_taxi/2020-03.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-04.parquet ...\n",
      "File saved to: data/yellow_taxi/2020-04.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-05.parquet ...\n",
      "File saved to: data/yellow_taxi/2020-05.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-06.parquet ...\n",
      "File saved to: data/yellow_taxi/2020-06.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-07.parquet ...\n",
      "File saved to: data/yellow_taxi/2020-07.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-08.parquet ...\n",
      "File saved to: data/yellow_taxi/2020-08.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-09.parquet ...\n",
      "File saved to: data/yellow_taxi/2020-09.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-10.parquet ...\n",
      "File saved to: data/yellow_taxi/2020-10.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-11.parquet ...\n",
      "File saved to: data/yellow_taxi/2020-11.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-12.parquet ...\n",
      "File saved to: data/yellow_taxi/2020-12.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-01.parquet ...\n",
      "File saved to: data/yellow_taxi/2021-01.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet ...\n",
      "File saved to: data/yellow_taxi/2021-02.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-03.parquet ...\n",
      "File saved to: data/yellow_taxi/2021-03.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-04.parquet ...\n",
      "File saved to: data/yellow_taxi/2021-04.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-05.parquet ...\n",
      "File saved to: data/yellow_taxi/2021-05.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-06.parquet ...\n",
      "File saved to: data/yellow_taxi/2021-06.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-07.parquet ...\n",
      "File saved to: data/yellow_taxi/2021-07.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-08.parquet ...\n",
      "File saved to: data/yellow_taxi/2021-08.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-09.parquet ...\n",
      "File saved to: data/yellow_taxi/2021-09.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-10.parquet ...\n",
      "File saved to: data/yellow_taxi/2021-10.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-11.parquet ...\n",
      "File saved to: data/yellow_taxi/2021-11.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-12.parquet ...\n",
      "File saved to: data/yellow_taxi/2021-12.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet ...\n",
      "File saved to: data/yellow_taxi/2022-01.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet ...\n",
      "File saved to: data/yellow_taxi/2022-02.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-03.parquet ...\n",
      "File saved to: data/yellow_taxi/2022-03.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-04.parquet ...\n",
      "File saved to: data/yellow_taxi/2022-04.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-05.parquet ...\n",
      "File saved to: data/yellow_taxi/2022-05.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-06.parquet ...\n",
      "File saved to: data/yellow_taxi/2022-06.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-07.parquet ...\n",
      "File saved to: data/yellow_taxi/2022-07.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-08.parquet ...\n",
      "File saved to: data/yellow_taxi/2022-08.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-09.parquet ...\n",
      "File saved to: data/yellow_taxi/2022-09.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-10.parquet ...\n",
      "File saved to: data/yellow_taxi/2022-10.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-11.parquet ...\n",
      "File saved to: data/yellow_taxi/2022-11.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-12.parquet ...\n",
      "File saved to: data/yellow_taxi/2022-12.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet ...\n",
      "File saved to: data/yellow_taxi/2023-01.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet ...\n",
      "File saved to: data/yellow_taxi/2023-02.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-03.parquet ...\n",
      "File saved to: data/yellow_taxi/2023-03.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-04.parquet ...\n",
      "File saved to: data/yellow_taxi/2023-04.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-05.parquet ...\n",
      "File saved to: data/yellow_taxi/2023-05.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-06.parquet ...\n",
      "File saved to: data/yellow_taxi/2023-06.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-07.parquet ...\n",
      "File saved to: data/yellow_taxi/2023-07.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-08.parquet ...\n",
      "File saved to: data/yellow_taxi/2023-08.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-09.parquet ...\n",
      "File saved to: data/yellow_taxi/2023-09.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-10.parquet ...\n",
      "File saved to: data/yellow_taxi/2023-10.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-11.parquet ...\n",
      "File saved to: data/yellow_taxi/2023-11.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-12.parquet ...\n",
      "File saved to: data/yellow_taxi/2023-12.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet ...\n",
      "File saved to: data/yellow_taxi/2024-01.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-02.parquet ...\n",
      "File saved to: data/yellow_taxi/2024-02.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-03.parquet ...\n",
      "File saved to: data/yellow_taxi/2024-03.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-04.parquet ...\n",
      "File saved to: data/yellow_taxi/2024-04.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-05.parquet ...\n",
      "File saved to: data/yellow_taxi/2024-05.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-06.parquet ...\n",
      "File saved to: data/yellow_taxi/2024-06.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-07.parquet ...\n",
      "File saved to: data/yellow_taxi/2024-07.parquet\n",
      "Downloading Yellow Taxi file: https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-08.parquet ...\n",
      "File saved to: data/yellow_taxi/2024-08.parquet\n"
     ]
    }
   ],
   "source": [
    "# Generate the date range for Yellow Taxi and HVFHV datasets\n",
    "start_date = \"2020-01\"\n",
    "end_date = \"2024-08\"\n",
    "\n",
    "dates = []\n",
    "current_date = datetime.strptime(start_date, \"%Y-%m\")\n",
    "end_date_obj = datetime.strptime(end_date, \"%Y-%m\")\n",
    "\n",
    "while current_date <= end_date_obj:\n",
    "    dates.append(current_date.strftime(\"%Y-%m\"))\n",
    "    current_date += timedelta(days=31)  # Move to the next month\n",
    "    current_date = current_date.replace(day=1)\n",
    "\n",
    "# Base URLs for Yellow Taxi and HVFHV datasets\n",
    "yellow_taxi_base_url = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_\"\n",
    "hvhf_base_url = \"https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_\"\n",
    "\n",
    "# Save directories for Yellow Taxi and HVFHV data\n",
    "yellow_taxi_save_dir = \"data/yellow_taxi\"\n",
    "hvhf_save_dir = \"data/hvhf\"\n",
    "\n",
    "# Ensure the directories exist\n",
    "os.makedirs(yellow_taxi_save_dir, exist_ok=True)\n",
    "os.makedirs(hvhf_save_dir, exist_ok=True)\n",
    "\n",
    "# Download Yellow Taxi data\n",
    "for date in dates:\n",
    "    file_url = f\"{yellow_taxi_base_url}{date}.parquet\"\n",
    "    file_name = f\"{date}.parquet\"\n",
    "    local_file_path = os.path.join(yellow_taxi_save_dir, file_name)\n",
    "\n",
    "    print(f\"Downloading Yellow Taxi file: {file_url} ...\")\n",
    "    try:\n",
    "        response = requests.get(file_url, stream=True)\n",
    "        response.raise_for_status()\n",
    "        with open(local_file_path, \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=1024):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "        print(f\"File saved to: {local_file_path}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to download {file_url}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08e85e9d-0888-4464-b772-b38aab7e03ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-01.parquet ...\n",
      "File saved to: data/hvhf/2020-01.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-02.parquet ...\n",
      "File saved to: data/hvhf/2020-02.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-03.parquet ...\n",
      "File saved to: data/hvhf/2020-03.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-04.parquet ...\n",
      "File saved to: data/hvhf/2020-04.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-05.parquet ...\n",
      "File saved to: data/hvhf/2020-05.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-06.parquet ...\n",
      "File saved to: data/hvhf/2020-06.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-07.parquet ...\n",
      "File saved to: data/hvhf/2020-07.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-08.parquet ...\n",
      "File saved to: data/hvhf/2020-08.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-09.parquet ...\n",
      "File saved to: data/hvhf/2020-09.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-10.parquet ...\n",
      "File saved to: data/hvhf/2020-10.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-11.parquet ...\n",
      "File saved to: data/hvhf/2020-11.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-12.parquet ...\n",
      "File saved to: data/hvhf/2020-12.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-01.parquet ...\n",
      "File saved to: data/hvhf/2021-01.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-02.parquet ...\n",
      "File saved to: data/hvhf/2021-02.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-03.parquet ...\n",
      "File saved to: data/hvhf/2021-03.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-04.parquet ...\n",
      "File saved to: data/hvhf/2021-04.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-05.parquet ...\n",
      "File saved to: data/hvhf/2021-05.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-06.parquet ...\n",
      "File saved to: data/hvhf/2021-06.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-07.parquet ...\n",
      "File saved to: data/hvhf/2021-07.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-08.parquet ...\n",
      "File saved to: data/hvhf/2021-08.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-09.parquet ...\n",
      "File saved to: data/hvhf/2021-09.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-10.parquet ...\n",
      "File saved to: data/hvhf/2021-10.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-11.parquet ...\n",
      "File saved to: data/hvhf/2021-11.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-12.parquet ...\n",
      "File saved to: data/hvhf/2021-12.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-01.parquet ...\n",
      "File saved to: data/hvhf/2022-01.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-02.parquet ...\n",
      "File saved to: data/hvhf/2022-02.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-03.parquet ...\n",
      "File saved to: data/hvhf/2022-03.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-04.parquet ...\n",
      "File saved to: data/hvhf/2022-04.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-05.parquet ...\n",
      "File saved to: data/hvhf/2022-05.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-06.parquet ...\n",
      "File saved to: data/hvhf/2022-06.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-07.parquet ...\n",
      "File saved to: data/hvhf/2022-07.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-08.parquet ...\n",
      "File saved to: data/hvhf/2022-08.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-09.parquet ...\n",
      "File saved to: data/hvhf/2022-09.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-10.parquet ...\n",
      "File saved to: data/hvhf/2022-10.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-11.parquet ...\n",
      "File saved to: data/hvhf/2022-11.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-12.parquet ...\n",
      "File saved to: data/hvhf/2022-12.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-01.parquet ...\n",
      "File saved to: data/hvhf/2023-01.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-02.parquet ...\n",
      "File saved to: data/hvhf/2023-02.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-03.parquet ...\n",
      "File saved to: data/hvhf/2023-03.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-04.parquet ...\n",
      "File saved to: data/hvhf/2023-04.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-05.parquet ...\n",
      "File saved to: data/hvhf/2023-05.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-06.parquet ...\n",
      "File saved to: data/hvhf/2023-06.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-07.parquet ...\n",
      "File saved to: data/hvhf/2023-07.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-08.parquet ...\n",
      "File saved to: data/hvhf/2023-08.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-09.parquet ...\n",
      "File saved to: data/hvhf/2023-09.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-10.parquet ...\n",
      "File saved to: data/hvhf/2023-10.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-11.parquet ...\n",
      "File saved to: data/hvhf/2023-11.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-12.parquet ...\n",
      "File saved to: data/hvhf/2023-12.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-01.parquet ...\n",
      "File saved to: data/hvhf/2024-01.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-02.parquet ...\n",
      "File saved to: data/hvhf/2024-02.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-03.parquet ...\n",
      "File saved to: data/hvhf/2024-03.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-04.parquet ...\n",
      "File saved to: data/hvhf/2024-04.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-05.parquet ...\n",
      "File saved to: data/hvhf/2024-05.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-06.parquet ...\n",
      "File saved to: data/hvhf/2024-06.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-07.parquet ...\n",
      "File saved to: data/hvhf/2024-07.parquet\n",
      "Downloading HVFHV file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-08.parquet ...\n",
      "File saved to: data/hvhf/2024-08.parquet\n"
     ]
    }
   ],
   "source": [
    "# Download HVFHV data\n",
    "for date in dates:\n",
    "    file_url = f\"{hvhf_base_url}{date}.parquet\"\n",
    "    file_name = f\"{date}.parquet\"\n",
    "    local_file_path = os.path.join(hvhf_save_dir, file_name)\n",
    "\n",
    "    print(f\"Downloading HVFHV file: {file_url} ...\")\n",
    "    try:\n",
    "        response = requests.get(file_url, stream=True)\n",
    "        response.raise_for_status()\n",
    "        with open(local_file_path, \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=1024):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "        print(f\"File saved to: {local_file_path}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to download {file_url}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dff9f30-f5e6-47ee-a435-4cf68fd4a4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: data/yellow_taxi/2022-04.parquet\n",
      "Population size: 3599920\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2022-04.parquet\n",
      "Processing file: data/yellow_taxi/2021-08.parquet\n",
      "Population size: 2788757\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2021-08.parquet\n",
      "Processing file: data/yellow_taxi/2023-12.parquet\n",
      "Population size: 3376567\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2023-12.parquet\n",
      "Processing file: data/yellow_taxi/2023-02.parquet\n",
      "Population size: 2913955\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2023-02.parquet\n",
      "Processing file: data/yellow_taxi/2021-01.parquet\n",
      "Population size: 1369769\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2021-01.parquet\n",
      "Processing file: data/yellow_taxi/2021-11.parquet\n",
      "Population size: 3472949\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2021-11.parquet\n",
      "Processing file: data/yellow_taxi/2020-07.parquet\n",
      "Population size: 800412\n",
      "Calculated sample size: 384\n",
      "Processed file saved to: processed_data/yellow_taxi/2020-07.parquet\n",
      "Processing file: data/yellow_taxi/2021-10.parquet\n",
      "Population size: 3463504\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2021-10.parquet\n",
      "Processing file: data/yellow_taxi/2024-01.parquet\n",
      "Population size: 2964624\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2024-01.parquet\n",
      "Processing file: data/yellow_taxi/2020-06.parquet\n",
      "Population size: 549797\n",
      "Calculated sample size: 384\n",
      "Processed file saved to: processed_data/yellow_taxi/2020-06.parquet\n",
      "Processing file: data/yellow_taxi/2024-08.parquet\n",
      "Population size: 2979183\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2024-08.parquet\n",
      "Processing file: data/yellow_taxi/2022-05.parquet\n",
      "Population size: 3588295\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2022-05.parquet\n",
      "Processing file: data/yellow_taxi/2021-09.parquet\n",
      "Population size: 2963793\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2021-09.parquet\n",
      "Processing file: data/yellow_taxi/2023-03.parquet\n",
      "Population size: 3403766\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2023-03.parquet\n",
      "Processing file: data/yellow_taxi/2024-03.parquet\n",
      "Population size: 3582628\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2024-03.parquet\n",
      "Processing file: data/yellow_taxi/2021-02.parquet\n",
      "Population size: 1371709\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2021-02.parquet\n",
      "Processing file: data/yellow_taxi/2021-12.parquet\n",
      "Population size: 3214369\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2021-12.parquet\n",
      "Processing file: data/yellow_taxi/2020-04.parquet\n",
      "Population size: 238073\n",
      "Calculated sample size: 384\n",
      "Processed file saved to: processed_data/yellow_taxi/2020-04.parquet\n",
      "Processing file: data/yellow_taxi/2023-08.parquet\n",
      "Population size: 2824209\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2023-08.parquet\n",
      "Processing file: data/yellow_taxi/2022-07.parquet\n",
      "Population size: 3174394\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2022-07.parquet\n",
      "Processing file: data/yellow_taxi/2023-11.parquet\n",
      "Population size: 3339715\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2023-11.parquet\n",
      "Processing file: data/yellow_taxi/2023-01.parquet\n",
      "Population size: 3066766\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2023-01.parquet\n",
      "Processing file: data/yellow_taxi/2022-06.parquet\n",
      "Population size: 3558124\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2022-06.parquet\n",
      "Processing file: data/yellow_taxi/2023-10.parquet\n",
      "Population size: 3522285\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2023-10.parquet\n",
      "Processing file: data/yellow_taxi/2024-02.parquet\n",
      "Population size: 3007526\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2024-02.parquet\n",
      "Processing file: data/yellow_taxi/2021-03.parquet\n",
      "Population size: 1925152\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2021-03.parquet\n",
      "Processing file: data/yellow_taxi/2020-05.parquet\n",
      "Population size: 348415\n",
      "Calculated sample size: 384\n",
      "Processed file saved to: processed_data/yellow_taxi/2020-05.parquet\n",
      "Processing file: data/yellow_taxi/2023-09.parquet\n",
      "Population size: 2846722\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2023-09.parquet\n",
      "Processing file: data/yellow_taxi/2020-10.parquet\n",
      "Population size: 1681132\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2020-10.parquet\n",
      "Processing file: data/yellow_taxi/2024-07.parquet\n",
      "Population size: 3076903\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2024-07.parquet\n",
      "Processing file: data/yellow_taxi/2021-06.parquet\n",
      "Population size: 2834264\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2021-06.parquet\n",
      "Processing file: data/yellow_taxi/2023-05.parquet\n",
      "Population size: 3513649\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2023-05.parquet\n",
      "Processing file: data/yellow_taxi/2020-09.parquet\n",
      "Population size: 1341017\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2020-09.parquet\n",
      "Processing file: data/yellow_taxi/2022-03.parquet\n",
      "Population size: 3627882\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2022-03.parquet\n",
      "Processing file: data/yellow_taxi/2023-04.parquet\n",
      "Population size: 3288250\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2023-04.parquet\n",
      "Processing file: data/yellow_taxi/2020-08.parquet\n",
      "Population size: 1007286\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2020-08.parquet\n",
      "Processing file: data/yellow_taxi/2022-02.parquet\n",
      "Population size: 2979431\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2022-02.parquet\n",
      "Processing file: data/yellow_taxi/2022-12.parquet\n",
      "Population size: 3399549\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2022-12.parquet\n",
      "Processing file: data/yellow_taxi/2020-11.parquet\n",
      "Population size: 1509000\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2020-11.parquet\n",
      "Processing file: data/yellow_taxi/2020-01.parquet\n",
      "Population size: 6405008\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2020-01.parquet\n",
      "Processing file: data/yellow_taxi/2024-06.parquet\n",
      "Population size: 3539193\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2024-06.parquet\n",
      "Processing file: data/yellow_taxi/2021-07.parquet\n",
      "Population size: 2821746\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2021-07.parquet\n",
      "Processing file: data/yellow_taxi/2023-06.parquet\n",
      "Population size: 3307234\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2023-06.parquet\n",
      "Processing file: data/yellow_taxi/2022-10.parquet\n",
      "Population size: 3675411\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2022-10.parquet\n",
      "Processing file: data/yellow_taxi/2020-03.parquet\n",
      "Population size: 3007687\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2020-03.parquet\n",
      "Processing file: data/yellow_taxi/2021-05.parquet\n",
      "Population size: 2507109\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2021-05.parquet\n",
      "Processing file: data/yellow_taxi/2022-09.parquet\n",
      "Population size: 3183767\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2022-09.parquet\n",
      "Processing file: data/yellow_taxi/2024-04.parquet\n",
      "Population size: 3514289\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2024-04.parquet\n",
      "Processing file: data/yellow_taxi/2020-12.parquet\n",
      "Population size: 1461898\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2020-12.parquet\n",
      "Processing file: data/yellow_taxi/2020-02.parquet\n",
      "Population size: 6299367\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2020-02.parquet\n",
      "Processing file: data/yellow_taxi/2021-04.parquet\n",
      "Population size: 2171187\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2021-04.parquet\n",
      "Processing file: data/yellow_taxi/2022-08.parquet\n",
      "Population size: 3152677\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2022-08.parquet\n",
      "Processing file: data/yellow_taxi/2024-05.parquet\n",
      "Population size: 3723833\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2024-05.parquet\n",
      "Processing file: data/yellow_taxi/2023-07.parquet\n",
      "Population size: 2907108\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2023-07.parquet\n",
      "Processing file: data/yellow_taxi/2022-01.parquet\n",
      "Population size: 2463931\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2022-01.parquet\n",
      "Processing file: data/yellow_taxi/2022-11.parquet\n",
      "Population size: 3252717\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/2022-11.parquet\n",
      "Processing file: data/hvhf/2022-04.parquet\n",
      "Filtered Uber rides: 13010980 out of 17752561 total rides.\n",
      "Population size: 13010980\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2022-04.parquet\n",
      "Processing file: data/hvhf/2021-08.parquet\n",
      "Filtered Uber rides: 10196747 out of 14499696 total rides.\n",
      "Population size: 10196747\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2021-08.parquet\n",
      "Processing file: data/hvhf/2023-12.parquet\n",
      "Filtered Uber rides: 14273626 out of 20516297 total rides.\n",
      "Population size: 14273626\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2023-12.parquet\n",
      "Processing file: data/hvhf/2023-02.parquet\n",
      "Filtered Uber rides: 13280939 out of 17960971 total rides.\n",
      "Population size: 13280939\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2023-02.parquet\n",
      "Processing file: data/hvhf/2021-01.parquet\n",
      "Filtered Uber rides: 8704128 out of 11908468 total rides.\n",
      "Population size: 8704128\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2021-01.parquet\n",
      "Processing file: data/hvhf/2021-11.parquet\n",
      "Filtered Uber rides: 11819597 out of 16041639 total rides.\n",
      "Population size: 11819597\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2021-11.parquet\n",
      "Processing file: data/hvhf/2020-07.parquet\n",
      "Filtered Uber rides: 7081522 out of 9958454 total rides.\n",
      "Population size: 7081522\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2020-07.parquet\n",
      "Processing file: data/hvhf/2021-10.parquet\n",
      "Filtered Uber rides: 12086389 out of 16545356 total rides.\n",
      "Population size: 12086389\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2021-10.parquet\n",
      "Processing file: data/hvhf/2024-01.parquet\n",
      "Filtered Uber rides: 14432755 out of 19663930 total rides.\n",
      "Population size: 14432755\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2024-01.parquet\n",
      "Processing file: data/hvhf/2020-06.parquet\n",
      "Filtered Uber rides: 5114308 out of 7555193 total rides.\n",
      "Population size: 5114308\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2020-06.parquet\n",
      "Processing file: data/hvhf/2024-08.parquet\n",
      "Filtered Uber rides: 14107392 out of 19128392 total rides.\n",
      "Population size: 14107392\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2024-08.parquet\n",
      "Processing file: data/hvhf/2022-05.parquet\n",
      "Filtered Uber rides: 13325434 out of 18157335 total rides.\n",
      "Population size: 13325434\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2022-05.parquet\n",
      "Processing file: data/hvhf/2021-09.parquet\n",
      "Filtered Uber rides: 10557442 out of 14886055 total rides.\n",
      "Population size: 10557442\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2021-09.parquet\n",
      "Processing file: data/hvhf/2023-03.parquet\n",
      "Filtered Uber rides: 14553368 out of 20413539 total rides.\n",
      "Population size: 14553368\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2023-03.parquet\n",
      "Processing file: data/hvhf/2024-03.parquet\n",
      "Filtered Uber rides: 15621998 out of 21280788 total rides.\n",
      "Population size: 15621998\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2024-03.parquet\n",
      "Processing file: data/hvhf/2021-02.parquet\n",
      "Filtered Uber rides: 8290758 out of 11613942 total rides.\n",
      "Population size: 8290758\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2021-02.parquet\n",
      "Processing file: data/hvhf/2021-12.parquet\n",
      "Filtered Uber rides: 11802074 out of 16054495 total rides.\n",
      "Population size: 11802074\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2021-12.parquet\n",
      "Processing file: data/hvhf/2020-04.parquet\n",
      "Filtered Uber rides: 3102835 out of 4312909 total rides.\n",
      "Population size: 3102835\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2020-04.parquet\n",
      "Processing file: data/hvhf/2023-08.parquet\n",
      "Filtered Uber rides: 13143169 out of 18322150 total rides.\n",
      "Population size: 13143169\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2023-08.parquet\n",
      "Processing file: data/hvhf/2022-07.parquet\n",
      "Filtered Uber rides: 12575713 out of 17464619 total rides.\n",
      "Population size: 12575713\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2022-07.parquet\n",
      "Processing file: data/hvhf/2023-11.parquet\n",
      "Filtered Uber rides: 13788773 out of 19269250 total rides.\n",
      "Population size: 13788773\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2023-11.parquet\n",
      "Processing file: data/hvhf/2023-01.parquet\n",
      "Filtered Uber rides: 13580152 out of 18479031 total rides.\n",
      "Population size: 13580152\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2023-01.parquet\n",
      "Processing file: data/hvhf/2022-06.parquet\n",
      "Filtered Uber rides: 13049858 out of 17780075 total rides.\n",
      "Population size: 13049858\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2022-06.parquet\n",
      "Processing file: data/hvhf/2023-10.parquet\n",
      "Filtered Uber rides: 14375602 out of 20186330 total rides.\n",
      "Population size: 14375602\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2023-10.parquet\n",
      "Processing file: data/hvhf/2024-02.parquet\n",
      "Filtered Uber rides: 14409305 out of 19359148 total rides.\n",
      "Population size: 14409305\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2024-02.parquet\n",
      "Processing file: data/hvhf/2021-03.parquet\n",
      "Filtered Uber rides: 10173376 out of 14227393 total rides.\n",
      "Population size: 10173376\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2021-03.parquet\n",
      "Processing file: data/hvhf/2020-05.parquet\n",
      "Filtered Uber rides: 4359377 out of 6089999 total rides.\n",
      "Population size: 4359377\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2020-05.parquet\n",
      "Processing file: data/hvhf/2023-09.parquet\n",
      "Filtered Uber rides: 14311606 out of 19851123 total rides.\n",
      "Population size: 14311606\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2023-09.parquet\n",
      "Processing file: data/hvhf/2020-10.parquet\n",
      "Filtered Uber rides: 9797775 out of 13268411 total rides.\n",
      "Population size: 9797775\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2020-10.parquet\n",
      "Processing file: data/hvhf/2024-07.parquet\n",
      "Filtered Uber rides: 14328764 out of 19182934 total rides.\n",
      "Population size: 14328764\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2024-07.parquet\n",
      "Processing file: data/hvhf/2021-06.parquet\n",
      "Filtered Uber rides: 10747390 out of 14961892 total rides.\n",
      "Population size: 10747390\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2021-06.parquet\n",
      "Processing file: data/hvhf/2023-05.parquet\n",
      "Filtered Uber rides: 14277828 out of 19847676 total rides.\n",
      "Population size: 14277828\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2023-05.parquet\n",
      "Processing file: data/hvhf/2020-09.parquet\n",
      "Filtered Uber rides: 8847755 out of 12106669 total rides.\n",
      "Population size: 8847755\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2020-09.parquet\n",
      "Processing file: data/hvhf/2022-03.parquet\n",
      "Filtered Uber rides: 13136268 out of 18453548 total rides.\n",
      "Population size: 13136268\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2022-03.parquet\n",
      "Processing file: data/hvhf/2023-04.parquet\n",
      "Filtered Uber rides: 13998413 out of 19144903 total rides.\n",
      "Population size: 13998413\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2023-04.parquet\n",
      "Processing file: data/hvhf/2020-08.parquet\n",
      "Filtered Uber rides: 7856499 out of 11096852 total rides.\n",
      "Population size: 7856499\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2020-08.parquet\n",
      "Processing file: data/hvhf/2022-02.parquet\n",
      "Filtered Uber rides: 11440898 out of 16019283 total rides.\n",
      "Population size: 11440898\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2022-02.parquet\n",
      "Processing file: data/hvhf/2022-12.parquet\n",
      "Filtered Uber rides: 14007908 out of 19665847 total rides.\n",
      "Population size: 14007908\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2022-12.parquet\n",
      "Processing file: data/hvhf/2020-11.parquet\n",
      "Filtered Uber rides: 8375281 out of 11596865 total rides.\n",
      "Population size: 8375281\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2020-11.parquet\n",
      "Processing file: data/hvhf/2020-01.parquet\n",
      "Filtered Uber rides: 14582520 out of 20569368 total rides.\n",
      "Population size: 14582520\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2020-01.parquet\n",
      "Processing file: data/hvhf/2024-06.parquet\n",
      "Filtered Uber rides: 15158032 out of 20123226 total rides.\n",
      "Population size: 15158032\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2024-06.parquet\n",
      "Processing file: data/hvhf/2021-07.parquet\n",
      "Filtered Uber rides: 10704366 out of 15027174 total rides.\n",
      "Population size: 10704366\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2021-07.parquet\n",
      "Processing file: data/hvhf/2023-06.parquet\n",
      "Filtered Uber rides: 13811993 out of 19366619 total rides.\n",
      "Population size: 13811993\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2023-06.parquet\n",
      "Processing file: data/hvhf/2022-10.parquet\n",
      "Filtered Uber rides: 14102892 out of 19306090 total rides.\n",
      "Population size: 14102892\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2022-10.parquet\n",
      "Processing file: data/hvhf/2020-03.parquet\n",
      "Filtered Uber rides: 9836781 out of 13392928 total rides.\n",
      "Population size: 9836781\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2020-03.parquet\n",
      "Processing file: data/hvhf/2021-05.parquet\n",
      "Filtered Uber rides: 10808415 out of 14719171 total rides.\n",
      "Population size: 10808415\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2021-05.parquet\n",
      "Processing file: data/hvhf/2022-09.parquet\n",
      "Filtered Uber rides: 12902315 out of 17793551 total rides.\n",
      "Population size: 12902315\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2022-09.parquet\n",
      "Processing file: data/hvhf/2024-04.parquet\n",
      "Filtered Uber rides: 14704197 out of 19733038 total rides.\n",
      "Population size: 14704197\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2024-04.parquet\n",
      "Processing file: data/hvhf/2020-12.parquet\n",
      "Filtered Uber rides: 8486416 out of 11637123 total rides.\n",
      "Population size: 8486416\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2020-12.parquet\n",
      "Processing file: data/hvhf/2020-02.parquet\n",
      "Filtered Uber rides: 15743610 out of 21725100 total rides.\n",
      "Population size: 15743610\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2020-02.parquet\n",
      "Processing file: data/hvhf/2021-04.parquet\n",
      "Filtered Uber rides: 10238382 out of 14111371 total rides.\n",
      "Population size: 10238382\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2021-04.parquet\n",
      "Processing file: data/hvhf/2022-08.parquet\n",
      "Filtered Uber rides: 12500703 out of 17185687 total rides.\n",
      "Population size: 12500703\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2022-08.parquet\n",
      "Processing file: data/hvhf/2024-05.parquet\n",
      "Filtered Uber rides: 15538267 out of 20704538 total rides.\n",
      "Population size: 15538267\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2024-05.parquet\n",
      "Processing file: data/hvhf/2023-07.parquet\n",
      "Filtered Uber rides: 13731861 out of 19132131 total rides.\n",
      "Population size: 13731861\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2023-07.parquet\n",
      "Processing file: data/hvhf/2022-01.parquet\n",
      "Filtered Uber rides: 10826336 out of 14751591 total rides.\n",
      "Population size: 10826336\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2022-01.parquet\n",
      "Processing file: data/hvhf/2022-11.parquet\n",
      "Filtered Uber rides: 12968005 out of 18085896 total rides.\n",
      "Population size: 12968005\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/2022-11.parquet\n"
     ]
    }
   ],
   "source": [
    "def filter_uber_rides(hvhf_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters out non-Uber rides from the HVFHV dataset.\n",
    "\n",
    "    Args:\n",
    "        hvhf_data (pd.DataFrame): The raw HVFHV dataset.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered dataset containing only Uber rides.\n",
    "    \"\"\"\n",
    "    # Ensure 'Hvfhs_license_num' is treated as a string\n",
    "    hvhf_data['hvfhs_license_num'] = hvhf_data['hvfhs_license_num'].astype(str)\n",
    "    \n",
    "    # Filter rows where 'hvfhs_license_num' is 'HV0003' (Uber)\n",
    "    uber_only_data = hvhf_data[hvhf_data['hvfhs_license_num'] == 'HV0003'].copy()\n",
    "\n",
    "    print(f\"Filtered Uber rides: {len(uber_only_data)} out of {len(hvhf_data)} total rides.\")\n",
    "    \n",
    "    # Warning if no Uber rides are found\n",
    "    if uber_only_data.empty:\n",
    "        print(\"Warning: No Uber rides found after filtering.\")\n",
    "    \n",
    "    return uber_only_data\n",
    "\n",
    "\n",
    "def cochran_sample_size(population_size: int, confidence_level: float = 0.95, margin_of_error: float = 0.05, p: float = 0.5) -> int:\n",
    "    \"\"\"\n",
    "    Calculate the sample size using Cochran's formula.\n",
    "\n",
    "    Args:\n",
    "        population_size (int): The total number of data points in the population.\n",
    "        confidence_level (float): The confidence level (default is 0.95).\n",
    "        margin_of_error (float): The margin of error (default is 0.05).\n",
    "        p (float): The estimated proportion of the population.\n",
    "\n",
    "    Returns:\n",
    "        int: The calculated sample size.\n",
    "    \"\"\"\n",
    "    z = {0.90: 1.645, 0.95: 1.96, 0.99: 2.576}.get(confidence_level, 1.96)\n",
    "    numerator = (z ** 2) * p * (1 - p)\n",
    "    denominator = margin_of_error ** 2\n",
    "    sample_size = numerator / denominator\n",
    "\n",
    "    if population_size > 0:\n",
    "        adjusted_sample_size = sample_size / (1 + (sample_size - 1) / population_size)\n",
    "    else:\n",
    "        adjusted_sample_size = sample_size\n",
    "    \n",
    "    return int(np.ceil(adjusted_sample_size))\n",
    "\n",
    "\n",
    "def process_dataset(file_path: str, output_dir: str, filter_uber: bool = False, p: float = 0.5) -> None:\n",
    "    \"\"\"\n",
    "    Processes a dataset: loads, filters, samples, and saves the result.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the dataset file.\n",
    "        output_dir (str): Directory to save the processed file.\n",
    "        filter_uber (bool): Whether to filter for Uber rides (default is False).\n",
    "        p (float): The proportion of variability for sampling (default is 0.5).\n",
    "    \"\"\"\n",
    "    print(f\"Processing file: {file_path}\")\n",
    "    \n",
    "    # Load the dataset\n",
    "    data = pd.read_parquet(file_path)\n",
    "    \n",
    "    # Apply filtering for Uber rides if needed\n",
    "    if filter_uber:\n",
    "        data = filter_uber_rides(data)\n",
    "    \n",
    "    # Determine population size\n",
    "    population_size = len(data)\n",
    "    print(f\"Population size: {population_size}\")\n",
    "    \n",
    "    # Calculate sample size\n",
    "    sample_size = cochran_sample_size(population_size, confidence_level=0.95, margin_of_error=0.05, p=p)\n",
    "    print(f\"Calculated sample size: {sample_size}\")\n",
    "    \n",
    "    # Sample the dataset\n",
    "    sampled_data = data.sample(n=sample_size, random_state=42)\n",
    "    \n",
    "    # Save the sampled dataset\n",
    "    output_file = os.path.join(output_dir, os.path.basename(file_path))\n",
    "    sampled_data.to_parquet(output_file)\n",
    "    print(f\"Processed file saved to: {output_file}\")\n",
    "\n",
    "\n",
    "# Example Workflow\n",
    "\n",
    "# Input directories (where raw datasets are stored)\n",
    "yellow_taxi_dir = \"data/yellow_taxi\"\n",
    "hvhf_dir = \"data/hvhf\"\n",
    "\n",
    "# Output directories (where processed datasets will be saved)\n",
    "processed_yellow_taxi_dir = \"processed_data/yellow_taxi\"\n",
    "processed_hvhf_dir = \"processed_data/hvhf\"\n",
    "\n",
    "# Ensure output directories exist\n",
    "os.makedirs(processed_yellow_taxi_dir, exist_ok=True)\n",
    "os.makedirs(processed_hvhf_dir, exist_ok=True)\n",
    "\n",
    "# Process Yellow Taxi datasets (using p = 0.5)\n",
    "for file in os.listdir(yellow_taxi_dir):\n",
    "    if file.endswith(\".parquet\"):\n",
    "        process_dataset(\n",
    "            file_path=os.path.join(yellow_taxi_dir, file),\n",
    "            output_dir=processed_yellow_taxi_dir,\n",
    "            filter_uber=False,\n",
    "            p=0.5  # Higher variability for Yellow Taxi\n",
    "        )\n",
    "\n",
    "# Process HVFHV datasets (filter for Uber rides, using p = 0.4)\n",
    "for file in os.listdir(hvhf_dir):\n",
    "    if file.endswith(\".parquet\"):\n",
    "        process_dataset(\n",
    "            file_path=os.path.join(hvhf_dir, file),\n",
    "            output_dir=processed_hvhf_dir,\n",
    "            filter_uber=True,\n",
    "            p=0.4  # Lower variability for Uber rides\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "92ee9460-92ca-4500-8b53-3170d06ebf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_monthly_files(data_dir: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Combines all Parquet files in the specified directory into a single DataFrame.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): Directory containing the monthly Parquet files.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A combined DataFrame with data from all monthly files.\n",
    "    \"\"\"\n",
    "    # List to store DataFrames for each file\n",
    "    data_frames = []\n",
    "\n",
    "    # Iterate through all Parquet files in the directory\n",
    "    for file in os.listdir(data_dir):\n",
    "        if file.endswith(\".parquet\"):\n",
    "            file_path = os.path.join(data_dir, file)\n",
    "            monthly_data = pd.read_parquet(file_path)\n",
    "            data_frames.append(monthly_data)\n",
    "\n",
    "    # Combine all DataFrames into one\n",
    "    combined_data = pd.concat(data_frames, ignore_index=True)\n",
    "    \n",
    "    return combined_data\n",
    "\n",
    "# Directories for processed data\n",
    "processed_yellow_taxi_dir = \"processed_data/yellow_taxi\"\n",
    "processed_hvhf_dir = \"processed_data/hvhf\"\n",
    "\n",
    "# Combine Yellow Taxi data\n",
    "yellow_taxi_data = combine_monthly_files(processed_yellow_taxi_dir)\n",
    "\n",
    "# Combine Uber (HVFHV) data\n",
    "uber_data = combine_monthly_files(processed_hvhf_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2ce480fe-92d9-4f12-b7da-ca8d98849723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>Airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-04-29 21:40:49</td>\n",
       "      <td>2022-04-29 21:46:33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>229</td>\n",
       "      <td>161</td>\n",
       "      <td>2</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.80</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-04-04 14:27:06</td>\n",
       "      <td>2022-04-04 15:13:35</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>35.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>45.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-04-10 09:32:27</td>\n",
       "      <td>2022-04-10 09:43:42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>262</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>9.50</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17.80</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-04-19 09:35:44</td>\n",
       "      <td>2022-04-19 09:55:06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>48</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>18.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-04-04 12:50:04</td>\n",
       "      <td>2022-04-04 12:50:07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>45.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>54.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21551</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-11-08 13:33:25</td>\n",
       "      <td>2022-11-08 13:51:41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>11.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21552</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-11-05 02:10:01</td>\n",
       "      <td>2022-11-05 02:18:51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>114</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>9.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15.96</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21553</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-11-08 21:35:31</td>\n",
       "      <td>2022-11-08 21:43:23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>148</td>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.80</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21554</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-11-12 04:34:04</td>\n",
       "      <td>2022-11-12 04:55:38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>48</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>30.50</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.15</td>\n",
       "      <td>6.55</td>\n",
       "      <td>0.3</td>\n",
       "      <td>49.00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21555</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-11-14 08:50:21</td>\n",
       "      <td>2022-11-14 09:07:28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>246</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>14.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21556 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0             2  2022-04-29 21:40:49   2022-04-29 21:46:33              1.0   \n",
       "1             2  2022-04-04 14:27:06   2022-04-04 15:13:35              6.0   \n",
       "2             1  2022-04-10 09:32:27   2022-04-10 09:43:42              1.0   \n",
       "3             2  2022-04-19 09:35:44   2022-04-19 09:55:06              1.0   \n",
       "4             2  2022-04-04 12:50:04   2022-04-04 12:50:07              2.0   \n",
       "...         ...                  ...                   ...              ...   \n",
       "21551         2  2022-11-08 13:33:25   2022-11-08 13:51:41              1.0   \n",
       "21552         2  2022-11-05 02:10:01   2022-11-05 02:18:51              1.0   \n",
       "21553         2  2022-11-08 21:35:31   2022-11-08 21:43:23              1.0   \n",
       "21554         1  2022-11-12 04:34:04   2022-11-12 04:55:38              1.0   \n",
       "21555         2  2022-11-14 08:50:21   2022-11-14 09:07:28              NaN   \n",
       "\n",
       "       trip_distance  RatecodeID store_and_fwd_flag  PULocationID  \\\n",
       "0               0.61         1.0                  N           229   \n",
       "1              10.16         1.0                  N           138   \n",
       "2               2.00         1.0                  N           262   \n",
       "3               3.20         1.0                  N            48   \n",
       "4               0.00         5.0                  N             7   \n",
       "...              ...         ...                ...           ...   \n",
       "21551           1.03         1.0                  N            43   \n",
       "21552           2.50         1.0                  N           114   \n",
       "21553           1.23         1.0                  N           148   \n",
       "21554          10.30         1.0                  N            48   \n",
       "21555           2.26         NaN               None           246   \n",
       "\n",
       "       DOLocationID  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
       "0               161             2         5.00    0.5      0.5        0.00   \n",
       "1                65             1        35.50    0.0      0.5        7.51   \n",
       "2                43             1         9.50    2.5      0.5        5.00   \n",
       "3                75             2        15.00    0.0      0.5        0.00   \n",
       "4               138             1        45.00    0.0      0.0        9.06   \n",
       "...             ...           ...          ...    ...      ...         ...   \n",
       "21551            43             1        11.00    0.0      0.5        0.00   \n",
       "21552            13             1         9.50    0.5      0.5        2.66   \n",
       "21553           231             1         7.00    0.5      0.5        1.00   \n",
       "21554           138             1        30.50    3.0      0.5        8.15   \n",
       "21555           161             0        14.93    0.0      0.5        2.54   \n",
       "\n",
       "       tolls_amount  improvement_surcharge  total_amount  \\\n",
       "0              0.00                    0.3          8.80   \n",
       "1              0.00                    0.3         45.06   \n",
       "2              0.00                    0.3         17.80   \n",
       "3              0.00                    0.3         18.30   \n",
       "4              0.00                    0.3         54.36   \n",
       "...             ...                    ...           ...   \n",
       "21551          0.00                    0.3         14.30   \n",
       "21552          0.00                    0.3         15.96   \n",
       "21553          0.00                    0.3         11.80   \n",
       "21554          6.55                    0.3         49.00   \n",
       "21555          0.00                    0.3         20.77   \n",
       "\n",
       "       congestion_surcharge  airport_fee  Airport_fee  \n",
       "0                       2.5         0.00          NaN  \n",
       "1                       0.0         1.25          NaN  \n",
       "2                       2.5         0.00          NaN  \n",
       "3                       2.5         0.00          NaN  \n",
       "4                       0.0         0.00          NaN  \n",
       "...                     ...          ...          ...  \n",
       "21551                   2.5         0.00          NaN  \n",
       "21552                   2.5         0.00          NaN  \n",
       "21553                   2.5         0.00          NaN  \n",
       "21554                   2.5         0.00          NaN  \n",
       "21555                   NaN          NaN          NaN  \n",
       "\n",
       "[21556 rows x 20 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yellow_taxi_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d53e24",
   "metadata": {},
   "source": [
    "### Load Taxi Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "58708809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_taxi_zones(file_path):\n",
    "    geofile = gpd.read_file(file_path)\n",
    "    return geofile\n",
    "    \n",
    "taxi_zones = load_taxi_zones(\"taxi_zones.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8d04c726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_coords_for_taxi_zone_id(zone_loc_id, loaded_taxi_zones):\n",
    "    zone = loaded_taxi_zones[loaded_taxi_zones['LocationID'] == zone_loc_id]\n",
    "    \n",
    "    # If no match is found, return None\n",
    "    if zone.empty:\n",
    "        return None\n",
    "    \n",
    "    # Get the centroid of the zone's geometry\n",
    "    centroid = zone.geometry.centroid.iloc[0]\n",
    "    \n",
    "    # Return the latitude and longitude as a tuple\n",
    "    return (centroid.y, centroid.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32074561",
   "metadata": {},
   "source": [
    "### Calculate Sample Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4cbbe6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sample_size(population, p = 0.5) -> int:\n",
    "    \"\"\"\n",
    "    Calculates the required sample size using Cochran's formula.\n",
    "\n",
    "    Args:\n",
    "        population (int): The total population size.\n",
    "        confidence_level (float): Confidence level as a proportion (default is 0.95 for 95% confidence).\n",
    "        margin_of_error (float): Desired margin of error as a proportion (default is 0.05 for 5%).\n",
    "\n",
    "    Returns:\n",
    "        int: Calculated sample size.\n",
    "    \"\"\"\n",
    "    # Z-value for confidence level (default: 1.96 for 95%)\n",
    "    z = 1.96\n",
    "    margin_of_error = 0.05\n",
    "    q = 1 - p  # Complementary proportion\n",
    "    \n",
    "    # Cochran's sample size formula for infinite population\n",
    "    n_0 = (z**2 * p * q) / (margin_of_error**2)\n",
    "    \n",
    "    # Adjust for finite population size\n",
    "    sample_size = n_0 / (1 + (n_0 - 1) / population)\n",
    "    \n",
    "    return math.ceil(sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc33eed4-b2e9-4ab3-94a8-59f04e464c98",
   "metadata": {},
   "source": [
    "### Common Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1dd682b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_urls_from_page(page_url):\n",
    "    \"\"\"\n",
    "    Fetches all URLs from a given webpage.\n",
    "\n",
    "    Args:\n",
    "        page_url (str): URL of the webpage to scrape.\n",
    "\n",
    "    Returns:\n",
    "        list: List of all URLs found on the webpage.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Send a GET request to the page\n",
    "        response = requests.get(page_url)\n",
    "        response.raise_for_status()  # Raise an HTTPError for bad responses\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise Exception(f\"Failed to access the URL: {page_url}. Error: {e}\")\n",
    "    \n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    # Find all anchor tags with href attributes\n",
    "    links = soup.find_all(\"a\", href=True)\n",
    "    \n",
    "    # Extract and return all href attributes\n",
    "    all_urls = [link[\"href\"] for link in links]\n",
    "    \n",
    "    return all_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cbd0d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_parquet_urls(links):\n",
    "    parquet_urls = []\n",
    "    for url in links:\n",
    "        # Normalize the URL (strip whitespace, handle cases like trailing slashes)\n",
    "        url = url.strip()\n",
    "        # Use regex to ensure matching even with query parameters\n",
    "        if re.search(r\"\\.parquet(\\?.*)?$\", url):\n",
    "            parquet_urls.append(url)\n",
    "    return parquet_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93daa717",
   "metadata": {},
   "source": [
    "### Process Taxi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2f40130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_taxi_month(parquet_url: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Downloads, processes, and saves Yellow Taxi dataset for a given month.\n",
    "\n",
    "    Args:\n",
    "        parquet_url (str): URL of the Yellow Taxi Parquet file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Sampled and processed DataFrame.\n",
    "    \"\"\"\n",
    "    # Default directory for processed Yellow Taxi data\n",
    "    save_dir = \"processed_data/yellow_taxi\"\n",
    "\n",
    "    # Ensure the save directory exists\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Extract file name and define local path\n",
    "    file_name = parquet_url.split(\"/\")[-1]\n",
    "    local_file_path = os.path.join(save_dir, file_name)\n",
    "\n",
    "    # Download the file if not already downloaded\n",
    "    if not os.path.exists(local_file_path):\n",
    "        print(f\"Downloading Yellow Taxi file: {parquet_url} ...\")\n",
    "        try:\n",
    "            response = requests.get(parquet_url, stream=True)\n",
    "            response.raise_for_status()\n",
    "            with open(local_file_path, \"wb\") as f:\n",
    "                for chunk in response.iter_content(chunk_size=1024 * 1024):  # 1MB chunks\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "            print(f\"File saved to: {local_file_path}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to download {parquet_url}: {e}\")\n",
    "            return pd.DataFrame()  # Return an empty DataFrame if download fails\n",
    "    else:\n",
    "        print(f\"Loading file from local storage: {local_file_path}\")\n",
    "\n",
    "    # Load the dataset\n",
    "    try:\n",
    "        data = pd.read_parquet(local_file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading Parquet file {local_file_path}: {e}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if reading fails\n",
    "\n",
    "    # Determine population size\n",
    "    population = len(data)\n",
    "    print(f\"Population size: {population}\")\n",
    "\n",
    "    # Calculate sample size (using p = 0.5 for Yellow Taxi data)\n",
    "    sample_size = calculate_sample_size(population, p = 0.5)\n",
    "    print(f\"Calculated sample size: {sample_size}\")\n",
    "\n",
    "    # Sample the dataset\n",
    "    sampled_data = data.sample(n=sample_size, random_state=42) if population > sample_size else data\n",
    "\n",
    "    # Save the sampled dataset\n",
    "    processed_file_path = os.path.join(save_dir, f\"sampled_{file_name}\")\n",
    "    sampled_data.to_parquet(processed_file_path)\n",
    "    print(f\"Processed file saved to: {processed_file_path}\")\n",
    "\n",
    "    return sampled_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "35c9c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_taxi_data(parquet_urls):\n",
    "    all_taxi_dataframes = []\n",
    "    yellow_taxi_pattern = re.compile(r\"yellow_tripdata_(2020-(0[1-9]|1[0-2])|202[1-3]-(0[1-9]|1[0-2])|2024-(0[1-8]))\\.parquet\")\n",
    "\n",
    "    # Filter URLs matching the pattern\n",
    "    yellow_taxi_urls = [url for url in parquet_urls if yellow_taxi_pattern.search(url)]\n",
    "    \n",
    "    for url in yellow_taxi_urls:\n",
    "        # maybe: first try to see if you've downloaded this exact\n",
    "        # file already and saved it before trying again\n",
    "        dataframe = get_and_clean_taxi_month(url)\n",
    "        # maybe: if the file hasn't been saved, save it so you can\n",
    "        # avoid re-downloading it if you re-run the function\n",
    "        \n",
    "        all_taxi_dataframes.append(dataframe)\n",
    "        \n",
    "    # create one gigantic dataframe with data from every month needed\n",
    "    taxi_data = pd.concat(all_taxi_dataframes)\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "200776ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_taxi_data():\n",
    "    all_urls = get_all_urls_from_page(TLC_URL)\n",
    "    all_parquet_urls = filter_parquet_urls(all_urls)\n",
    "    taxi_data = get_and_clean_taxi_data(all_parquet_urls)\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "876bd645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2024-01.parquet\n",
      "Population size: 2964624\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2024-01.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2024-02.parquet\n",
      "Population size: 3007526\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2024-02.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2024-03.parquet\n",
      "Population size: 3582628\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2024-03.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2024-04.parquet\n",
      "Population size: 3514289\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2024-04.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2024-05.parquet\n",
      "Population size: 3723833\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2024-05.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2024-06.parquet\n",
      "Population size: 3539193\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2024-06.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2024-07.parquet\n",
      "Population size: 3076903\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2024-07.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2024-08.parquet\n",
      "Population size: 2979183\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2024-08.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2023-01.parquet\n",
      "Population size: 3066766\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2023-01.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2023-02.parquet\n",
      "Population size: 2913955\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2023-02.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2023-03.parquet\n",
      "Population size: 3403766\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2023-03.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2023-04.parquet\n",
      "Population size: 3288250\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2023-04.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2023-05.parquet\n",
      "Population size: 3513649\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2023-05.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2023-06.parquet\n",
      "Population size: 3307234\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2023-06.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2023-07.parquet\n",
      "Population size: 2907108\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2023-07.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2023-08.parquet\n",
      "Population size: 2824209\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2023-08.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2023-09.parquet\n",
      "Population size: 2846722\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2023-09.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2023-10.parquet\n",
      "Population size: 3522285\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2023-10.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2023-11.parquet\n",
      "Population size: 3339715\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2023-11.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2023-12.parquet\n",
      "Population size: 3376567\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2023-12.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2022-01.parquet\n",
      "Population size: 2463931\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2022-01.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2022-02.parquet\n",
      "Population size: 2979431\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2022-02.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2022-03.parquet\n",
      "Population size: 3627882\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2022-03.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2022-04.parquet\n",
      "Population size: 3599920\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2022-04.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2022-05.parquet\n",
      "Population size: 3588295\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2022-05.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2022-06.parquet\n",
      "Population size: 3558124\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2022-06.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2022-07.parquet\n",
      "Population size: 3174394\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2022-07.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2022-08.parquet\n",
      "Population size: 3152677\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2022-08.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2022-09.parquet\n",
      "Population size: 3183767\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2022-09.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2022-10.parquet\n",
      "Population size: 3675411\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2022-10.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2022-11.parquet\n",
      "Population size: 3252717\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2022-11.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2022-12.parquet\n",
      "Population size: 3399549\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2022-12.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2021-01.parquet\n",
      "Population size: 1369769\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2021-01.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2021-02.parquet\n",
      "Population size: 1371709\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2021-02.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2021-03.parquet\n",
      "Population size: 1925152\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2021-03.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2021-04.parquet\n",
      "Population size: 2171187\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2021-04.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2021-05.parquet\n",
      "Population size: 2507109\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2021-05.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2021-06.parquet\n",
      "Population size: 2834264\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2021-06.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2021-07.parquet\n",
      "Population size: 2821746\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2021-07.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2021-08.parquet\n",
      "Population size: 2788757\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2021-08.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2021-09.parquet\n",
      "Population size: 2963793\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2021-09.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2021-10.parquet\n",
      "Population size: 3463504\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2021-10.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2021-11.parquet\n",
      "Population size: 3472949\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2021-11.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2021-12.parquet\n",
      "Population size: 3214369\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2021-12.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2020-01.parquet\n",
      "Population size: 6405008\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2020-01.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2020-02.parquet\n",
      "Population size: 6299367\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2020-02.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2020-03.parquet\n",
      "Population size: 3007687\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2020-03.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2020-04.parquet\n",
      "Population size: 238073\n",
      "Calculated sample size: 384\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2020-04.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2020-05.parquet\n",
      "Population size: 348415\n",
      "Calculated sample size: 384\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2020-05.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2020-06.parquet\n",
      "Population size: 549797\n",
      "Calculated sample size: 384\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2020-06.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2020-07.parquet\n",
      "Population size: 800412\n",
      "Calculated sample size: 384\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2020-07.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2020-08.parquet\n",
      "Population size: 1007286\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2020-08.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2020-09.parquet\n",
      "Population size: 1341017\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2020-09.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2020-10.parquet\n",
      "Population size: 1681132\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2020-10.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2020-11.parquet\n",
      "Population size: 1509000\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2020-11.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2020-12.parquet\n",
      "Population size: 1461898\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2020-12.parquet\n"
     ]
    }
   ],
   "source": [
    "taxi_data = get_taxi_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "10ebd75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>Airport_fee</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1725696</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-20 13:31:30</td>\n",
       "      <td>2024-01-20 14:03:25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>132</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.27</td>\n",
       "      <td>6.94</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.96</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.75</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581136</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-18 21:52:46</td>\n",
       "      <td>2024-01-18 22:03:21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>163</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>13.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.50</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19137</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-01 03:43:58</td>\n",
       "      <td>2024-01-01 03:50:47</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>127</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682810</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-19 22:20:12</td>\n",
       "      <td>2024-01-19 22:50:12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>186</td>\n",
       "      <td>263</td>\n",
       "      <td>1</td>\n",
       "      <td>23.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.95</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511035</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-06 22:41:50</td>\n",
       "      <td>2024-01-06 22:43:24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "1725696         2  2024-01-20 13:31:30   2024-01-20 14:03:25              2.0   \n",
       "1581136         2  2024-01-18 21:52:46   2024-01-18 22:03:21              1.0   \n",
       "19137           2  2024-01-01 03:43:58   2024-01-01 03:50:47              2.0   \n",
       "1682810         1  2024-01-19 22:20:12   2024-01-19 22:50:12              1.0   \n",
       "511035          2  2024-01-06 22:41:50   2024-01-06 22:43:24              1.0   \n",
       "\n",
       "         trip_distance  RatecodeID store_and_fwd_flag  PULocationID  \\\n",
       "1725696          17.14         2.0                  N           132   \n",
       "1581136           2.49         1.0                  N           163   \n",
       "19137             1.84         1.0                  N           127   \n",
       "1682810           3.60         1.0                  N           186   \n",
       "511035            0.04         1.0                  N           238   \n",
       "\n",
       "         DOLocationID  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
       "1725696           233             1         70.0    0.0      0.5        8.27   \n",
       "1581136            75             1         13.5    1.0      0.5        4.00   \n",
       "19137              20             2         10.0    1.0      0.5        0.00   \n",
       "1682810           263             1         23.3    3.5      0.5        5.65   \n",
       "511035            238             2          3.7    1.0      0.5        0.00   \n",
       "\n",
       "         tolls_amount  improvement_surcharge  total_amount  \\\n",
       "1725696          6.94                    1.0         90.96   \n",
       "1581136          0.00                    1.0         22.50   \n",
       "19137            0.00                    1.0         12.50   \n",
       "1682810          0.00                    1.0         33.95   \n",
       "511035           0.00                    1.0          6.20   \n",
       "\n",
       "         congestion_surcharge  Airport_fee  airport_fee  \n",
       "1725696                   2.5         1.75          NaN  \n",
       "1581136                   2.5         0.00          NaN  \n",
       "19137                     0.0         0.00          NaN  \n",
       "1682810                   2.5         0.00          NaN  \n",
       "511035                    0.0         0.00          NaN  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c9da7089-3f6b-4f93-a22e-76bf554daca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 21556 entries, 1725696 to 701728\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   VendorID               21556 non-null  int64         \n",
      " 1   tpep_pickup_datetime   21556 non-null  datetime64[ns]\n",
      " 2   tpep_dropoff_datetime  21556 non-null  datetime64[ns]\n",
      " 3   passenger_count        20381 non-null  float64       \n",
      " 4   trip_distance          21556 non-null  float64       \n",
      " 5   RatecodeID             20381 non-null  float64       \n",
      " 6   store_and_fwd_flag     20381 non-null  object        \n",
      " 7   PULocationID           21556 non-null  int64         \n",
      " 8   DOLocationID           21556 non-null  int64         \n",
      " 9   payment_type           21556 non-null  int64         \n",
      " 10  fare_amount            21556 non-null  float64       \n",
      " 11  extra                  21556 non-null  float64       \n",
      " 12  mta_tax                21556 non-null  float64       \n",
      " 13  tip_amount             21556 non-null  float64       \n",
      " 14  tolls_amount           21556 non-null  float64       \n",
      " 15  improvement_surcharge  21556 non-null  float64       \n",
      " 16  total_amount           21556 non-null  float64       \n",
      " 17  congestion_surcharge   20381 non-null  float64       \n",
      " 18  Airport_fee            6853 non-null   float64       \n",
      " 19  airport_fee            8201 non-null   float64       \n",
      "dtypes: datetime64[ns](2), float64(13), int64(4), object(1)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "taxi_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "50c85e25-6416-4c16-b98c-09596cdc6865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>Airport_fee</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21556.000000</td>\n",
       "      <td>21556</td>\n",
       "      <td>21556</td>\n",
       "      <td>20381.000000</td>\n",
       "      <td>21556.000000</td>\n",
       "      <td>20381.000000</td>\n",
       "      <td>21556.000000</td>\n",
       "      <td>21556.000000</td>\n",
       "      <td>21556.000000</td>\n",
       "      <td>21556.000000</td>\n",
       "      <td>21556.000000</td>\n",
       "      <td>21556.000000</td>\n",
       "      <td>21556.000000</td>\n",
       "      <td>21556.000000</td>\n",
       "      <td>21556.000000</td>\n",
       "      <td>21556.000000</td>\n",
       "      <td>20381.000000</td>\n",
       "      <td>6853.000000</td>\n",
       "      <td>8201.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.719197</td>\n",
       "      <td>2022-05-01 19:16:50.909073920</td>\n",
       "      <td>2022-05-01 19:33:07.142048512</td>\n",
       "      <td>1.399980</td>\n",
       "      <td>3.292046</td>\n",
       "      <td>1.468132</td>\n",
       "      <td>165.086472</td>\n",
       "      <td>161.552282</td>\n",
       "      <td>1.184682</td>\n",
       "      <td>15.582768</td>\n",
       "      <td>1.192449</td>\n",
       "      <td>0.488194</td>\n",
       "      <td>2.692410</td>\n",
       "      <td>0.451578</td>\n",
       "      <td>0.542666</td>\n",
       "      <td>22.609807</td>\n",
       "      <td>2.265958</td>\n",
       "      <td>0.140668</td>\n",
       "      <td>0.090690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2009-01-01 01:11:17</td>\n",
       "      <td>2009-01-01 01:11:20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-250.000000</td>\n",
       "      <td>-7.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.130000</td>\n",
       "      <td>-34.200000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-251.000000</td>\n",
       "      <td>-2.500000</td>\n",
       "      <td>-1.750000</td>\n",
       "      <td>-1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2021-03-01 12:26:32.750000128</td>\n",
       "      <td>2021-03-01 12:34:07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2022-05-01 13:35:11.500000</td>\n",
       "      <td>2022-05-01 14:01:36.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.700000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>17.020000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2023-07-01 00:03:05</td>\n",
       "      <td>2023-07-01 00:12:55.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.440000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.800000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>2024-08-31 23:00:33</td>\n",
       "      <td>2024-08-31 23:34:12</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>67.900000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>265.000000</td>\n",
       "      <td>265.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>278.800000</td>\n",
       "      <td>11.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>51.150000</td>\n",
       "      <td>57.050000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>289.350000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.493676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.981261</td>\n",
       "      <td>4.272702</td>\n",
       "      <td>6.286294</td>\n",
       "      <td>65.699489</td>\n",
       "      <td>70.905294</td>\n",
       "      <td>0.568066</td>\n",
       "      <td>15.408238</td>\n",
       "      <td>1.511804</td>\n",
       "      <td>0.097580</td>\n",
       "      <td>3.282479</td>\n",
       "      <td>1.909912</td>\n",
       "      <td>0.353155</td>\n",
       "      <td>19.130045</td>\n",
       "      <td>0.780689</td>\n",
       "      <td>0.479079</td>\n",
       "      <td>0.330094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           VendorID           tpep_pickup_datetime  \\\n",
       "count  21556.000000                          21556   \n",
       "mean       1.719197  2022-05-01 19:16:50.909073920   \n",
       "min        1.000000            2009-01-01 01:11:17   \n",
       "25%        1.000000  2021-03-01 12:26:32.750000128   \n",
       "50%        2.000000     2022-05-01 13:35:11.500000   \n",
       "75%        2.000000            2023-07-01 00:03:05   \n",
       "max        6.000000            2024-08-31 23:00:33   \n",
       "std        0.493676                            NaN   \n",
       "\n",
       "               tpep_dropoff_datetime  passenger_count  trip_distance  \\\n",
       "count                          21556     20381.000000   21556.000000   \n",
       "mean   2022-05-01 19:33:07.142048512         1.399980       3.292046   \n",
       "min              2009-01-01 01:11:20         0.000000       0.000000   \n",
       "25%              2021-03-01 12:34:07         1.000000       1.050000   \n",
       "50%       2022-05-01 14:01:36.500000         1.000000       1.800000   \n",
       "75%       2023-07-01 00:12:55.500000         1.000000       3.310000   \n",
       "max              2024-08-31 23:34:12         6.000000      67.900000   \n",
       "std                              NaN         0.981261       4.272702   \n",
       "\n",
       "         RatecodeID  PULocationID  DOLocationID  payment_type   fare_amount  \\\n",
       "count  20381.000000  21556.000000  21556.000000  21556.000000  21556.000000   \n",
       "mean       1.468132    165.086472    161.552282      1.184682     15.582768   \n",
       "min        1.000000      4.000000      1.000000      0.000000   -250.000000   \n",
       "25%        1.000000    132.000000    107.000000      1.000000      7.200000   \n",
       "50%        1.000000    162.000000    162.000000      1.000000     10.700000   \n",
       "75%        1.000000    234.000000    234.000000      1.000000     17.500000   \n",
       "max       99.000000    265.000000    265.000000      4.000000    278.800000   \n",
       "std        6.286294     65.699489     70.905294      0.568066     15.408238   \n",
       "\n",
       "              extra       mta_tax    tip_amount  tolls_amount  \\\n",
       "count  21556.000000  21556.000000  21556.000000  21556.000000   \n",
       "mean       1.192449      0.488194      2.692410      0.451578   \n",
       "min       -7.500000     -0.500000     -0.130000    -34.200000   \n",
       "25%        0.000000      0.500000      0.000000      0.000000   \n",
       "50%        0.500000      0.500000      2.150000      0.000000   \n",
       "75%        2.500000      0.500000      3.440000      0.000000   \n",
       "max       11.750000      0.500000     51.150000     57.050000   \n",
       "std        1.511804      0.097580      3.282479      1.909912   \n",
       "\n",
       "       improvement_surcharge  total_amount  congestion_surcharge  Airport_fee  \\\n",
       "count           21556.000000  21556.000000          20381.000000  6853.000000   \n",
       "mean                0.542666     22.609807              2.265958     0.140668   \n",
       "min                -1.000000   -251.000000             -2.500000    -1.750000   \n",
       "25%                 0.300000     12.600000              2.500000     0.000000   \n",
       "50%                 0.300000     17.020000              2.500000     0.000000   \n",
       "75%                 1.000000     24.800000              2.500000     0.000000   \n",
       "max                 1.000000    289.350000              2.500000     1.750000   \n",
       "std                 0.353155     19.130045              0.780689     0.479079   \n",
       "\n",
       "       airport_fee  \n",
       "count  8201.000000  \n",
       "mean      0.090690  \n",
       "min      -1.250000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.000000  \n",
       "max       1.250000  \n",
       "std       0.330094  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094b4d6d",
   "metadata": {},
   "source": [
    "### Processing Uber Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07574983-f41d-4cd6-8f70-489493089b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_uber_month(parquet_url):\n",
    "    save_dir = \"processed_data/hvhf\"\n",
    "\n",
    "    # Ensure the save directory exists\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Extract file name and define local path\n",
    "    file_name = parquet_url.split(\"/\")[-1]\n",
    "    local_file_path = os.path.join(save_dir, file_name)\n",
    "\n",
    "    # Download the file if not already downloaded\n",
    "    if not os.path.exists(local_file_path):\n",
    "        print(f\"Downloading HVHF file: {parquet_url} ...\")\n",
    "        try:\n",
    "            response = requests.get(parquet_url, stream=True)\n",
    "            response.raise_for_status()\n",
    "            with open(local_file_path, \"wb\") as f:\n",
    "                for chunk in response.iter_content(chunk_size=1024 * 1024):  # 1MB chunks\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "            print(f\"File saved to: {local_file_path}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to download {parquet_url}: {e}\")\n",
    "            return pd.DataFrame()  # Return an empty DataFrame if download fails\n",
    "    else:\n",
    "        print(f\"Loading file from local storage: {local_file_path}\")\n",
    "\n",
    "    # Load the dataset\n",
    "    try:\n",
    "        data = pd.read_parquet(local_file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading Parquet file {local_file_path}: {e}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if reading fails\n",
    "\n",
    "    # Determine population size\n",
    "    population = len(data)\n",
    "    print(f\"Population size: {population}\")\n",
    "\n",
    "    # Calculate sample size (using p = 0.5 for Yellow Taxi data)\n",
    "    sample_size = calculate_sample_size(population, p = 0.4)\n",
    "    print(f\"Calculated sample size: {sample_size}\")\n",
    "\n",
    "    # Sample the dataset\n",
    "    sampled_data = data.sample(n=sample_size, random_state=42) if population > sample_size else data\n",
    "\n",
    "    # Save the sampled dataset\n",
    "    processed_file_path = os.path.join(save_dir, f\"sampled_{file_name}\")\n",
    "    sampled_data.to_parquet(processed_file_path)\n",
    "    print(f\"Processed file saved to: {processed_file_path}\")\n",
    "\n",
    "    return sampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3d85ff-313c-41a2-9a46-261a9a2bb10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_uber_data(parquet_urls):\n",
    "    all_uber_dataframes = []\n",
    "    hvfhv_pattern = re.compile(r\"fhvhv_tripdata_\\d{4}-\\d{2}\\.parquet\")\n",
    "    hvfhv_urls = [url for url in links if hvfhv_pattern.search(url)]\n",
    "    for url in hvfhv_urls:\n",
    "        # maybe: first try to see if you've downloaded this exact\n",
    "        # file already and saved it before trying again\n",
    "        dataframe = get_and_clean_uber_month(url)\n",
    "        # maybe: if the file hasn't been saved, save it so you can\n",
    "        # avoid re-downloading it if you re-run the function\n",
    "        \n",
    "        all_uber_dataframes.append(dataframe)\n",
    "        \n",
    "    # create one gigantic dataframe with data from every month needed\n",
    "    uber_data = pd.contact(all_uber_dataframes)\n",
    "    return uber_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c58e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_uber_data(dataframe):\n",
    "    uber_data['hvfhs_license_num'] = uber_data['hvfhs_license_num'].astype(str)\n",
    "    \n",
    "    # Filter rows where 'hvfhs_license_num' is 'HV0003' (Uber)\n",
    "    uber_only_data = uber_data[uber['hvfhs_license_num'] == 'HV0003'].copy()\n",
    "    return uber_only_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f836f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uber_data():\n",
    "    all_urls = get_all_urls_from_tlc_page(TLC_URL)\n",
    "    all_parquet_urls = find_parquet_urls(all_urls)\n",
    "    uber_data = get_and_clean_uber_data(all_parquet_urls)\n",
    "    taxi_data = load_and_clean_uber_data(uber_data)\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2bd13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_data = get_uber_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339997e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d783db-e527-4847-bf70-2d7428ea3897",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fddeb14-cd70-4e83-8f93-974642c3bea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a15cbb",
   "metadata": {},
   "source": [
    "### Processing Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec5370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_weather_csvs(directory):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e864ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_hourly(csv_file):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0687581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_daily(csv_file):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef8945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_weather_data():\n",
    "    weather_csv_files = get_all_weather_csvs(WEATHER_CSV_DIR)\n",
    "    \n",
    "    hourly_dataframes = []\n",
    "    daily_dataframes = []\n",
    "        \n",
    "    for csv_file in weather_csv_files:\n",
    "        hourly_dataframe = clean_month_weather_data_hourly(csv_file)\n",
    "        daily_dataframe = clean_month_weather_data_daily(csv_file)\n",
    "        hourly_dataframes.append(hourly_dataframe)\n",
    "        daily_dataframes.append(daily_dataframe)\n",
    "        \n",
    "    # create two dataframes with hourly & daily data from every month\n",
    "    hourly_data = pd.concat(hourly_dataframes)\n",
    "    daily_data = pd.concat(daily_dataframes)\n",
    "    \n",
    "    return hourly_data, daily_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cd53a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_weather_data, daily_weather_data = load_and_clean_weather_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48216557",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935261b7-ae23-427c-97ff-ea31aa4e44c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_weather_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dcb502-d1d1-447d-aa68-11bff0dc53b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_weather_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb386ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f090eb94-a5b0-4d93-bf82-a596d2521b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_weather_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c074aa3-a5f2-4586-8748-411e1e6c11da",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_weather_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd101f11",
   "metadata": {},
   "source": [
    "## Part 2: Storing Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3529cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bea0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using SQL (as opposed to SQLAlchemy), define the commands \n",
    "# to create your 4 tables/dataframes\n",
    "HOURLY_WEATHER_SCHEMA = \"\"\"\n",
    "TODO\n",
    "\"\"\"\n",
    "\n",
    "DAILY_WEATHER_SCHEMA = \"\"\"\n",
    "TODO\n",
    "\"\"\"\n",
    "\n",
    "TAXI_TRIPS_SCHEMA = \"\"\"\n",
    "TODO\n",
    "\"\"\"\n",
    "\n",
    "UBER_TRIPS_SCHEMA = \"\"\"\n",
    "TODO\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f41e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create that required schema.sql file\n",
    "with open(DATABASE_SCHEMA_FILE, \"w\") as f:\n",
    "    f.write(HOURLY_WEATHER_SCHEMA)\n",
    "    f.write(DAILY_WEATHER_SCHEMA)\n",
    "    f.write(TAXI_TRIPS_SCHEMA)\n",
    "    f.write(UBER_TRIPS_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eccdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tables with the schema files\n",
    "with engine.connect() as connection:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c122964f",
   "metadata": {},
   "source": [
    "### Add Data to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e68a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframes_to_table(table_to_df_dict):\n",
    "    raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d6c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_table_name_to_dataframe = {\n",
    "    \"taxi_trips\": taxi_data,\n",
    "    \"uber_trips\": uber_data,\n",
    "    \"hourly_weather\": hourly_data,\n",
    "    \"daily_weather\": daily_data,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74004f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframes_to_table(map_table_name_to_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb6e33e",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a849e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to write the queries to file\n",
    "def write_query_to_file(query, outfile):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee70a777",
   "metadata": {},
   "source": [
    "### Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db871d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_1_FILENAME = \"\"\n",
    "\n",
    "QUERY_1 = \"\"\"\n",
    "TODO\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5275f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute query either via sqlalchemy\n",
    "with engine.connect() as con:\n",
    "    results = con.execute(db.text(QUERY_1)).fetchall()\n",
    "results\n",
    "\n",
    "# or via pandas\n",
    "pd.read_sql(QUERY_1, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef04df",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_1, QUERY_1_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ced42",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9eef42",
   "metadata": {},
   "source": [
    "### Visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more descriptive name for your function\n",
    "def plot_visual_1(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ced2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_1():\n",
    "    # Query SQL database for the data needed.\n",
    "    # You can put the data queried into a pandas dataframe, if you wish\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_1()\n",
    "plot_visual_1(some_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
