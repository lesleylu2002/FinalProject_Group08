{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f8ca24",
   "metadata": {},
   "source": [
    "# Understanding Hired Rides in NYC\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75fd94",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66dcde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all import statements needed for the project, for example:\n",
    "\n",
    "import os\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import requests\n",
    "import sqlalchemy as db\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import math\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f1242c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any constants you might need; some have been added for you, and \n",
    "# some you need to fill in\n",
    "\n",
    "TLC_URL = \"https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "\n",
    "TAXI_ZONES_DIR = \"data/taxi_zones\"\n",
    "TAXI_ZONES_SHAPEFILE = f\"{TAXI_ZONES_DIR}/taxi_zones.shp\"\n",
    "WEATHER_CSV_DIR = \"data/weather\"\n",
    "\n",
    "CRS = 4326  # coordinate reference system\n",
    "\n",
    "# (lat, lon)\n",
    "NEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\n",
    "LGA_BOX_COORDS = ((40.763589, -73.891745), (40.778865, -73.854838))\n",
    "JFK_BOX_COORDS = ((40.639263, -73.795642), (40.651376, -73.766264))\n",
    "EWR_BOX_COORDS = ((40.686794, -74.194028), (40.699680, -74.165205))\n",
    "\n",
    "DATABASE_URL = \"sqlite:///project.db\"\n",
    "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "QUERY_DIRECTORY = \"queries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6601633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the QUERY_DIRECTORY exists\n",
    "try:\n",
    "    os.mkdir(QUERY_DIRECTORY)\n",
    "except Exception as e:\n",
    "    if e.errno == 17:\n",
    "        # the directory already exists\n",
    "        pass\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad10ea",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d53e24",
   "metadata": {},
   "source": [
    "### Load Taxi Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58708809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_taxi_zones(shapefile):\n",
    "    \"\"\"Reading taxi zones shapefile through geopandas.\"\"\"\n",
    "    geofile = gpd.read_file(shapfile)\n",
    "    return geofile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d04c726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_coords_for_taxi_zone_id(zone_loc_id, loaded_taxi_zones):\n",
    "    # Find the taxi zone id corresponding to the location id\n",
    "    zone = loaded_taxi_zones[loaded_taxi_zones['LocationID'] == zone_loc_id]\n",
    "    \n",
    "    # If no match is found, return None\n",
    "    if zone.empty:\n",
    "        return None\n",
    "    \n",
    "    # Get the centroid of the zone's geometry\n",
    "    centroid = zone.geometry.centroid.iloc[0]\n",
    "    \n",
    "    # Return the latitude and longitude as a tuple\n",
    "    return (centroid.y, centroid.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32074561",
   "metadata": {},
   "source": [
    "### Calculate Sample Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cbbe6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sample_size(population: int, confidence_level: float = 0.95, margin_of_error: float = 0.05, p: float = 0.5) -> int:\n",
    "    \"\"\"\n",
    "    Calculate the sample size using Cochran's formula.\n",
    "\n",
    "    Args:\n",
    "        population (int): The total number of data points in the population.\n",
    "        confidence_level (float): The confidence level (default is 0.95).\n",
    "        margin_of_error (float): The margin of error (default is 0.05).\n",
    "        p (float): The estimated proportion of the population.\n",
    "\n",
    "    Returns:\n",
    "        int: The calculated sample size.\n",
    "    \"\"\"\n",
    "    z = {0.90: 1.645, 0.95: 1.96, 0.99: 2.576}.get(confidence_level, 1.96)\n",
    "    numerator = (z ** 2) * p * (1 - p)\n",
    "    denominator = margin_of_error ** 2\n",
    "    sample_size = numerator / denominator\n",
    "\n",
    "    if population > 0:\n",
    "        adjusted_sample_size = sample_size / (1 + (sample_size - 1) / population)\n",
    "    else:\n",
    "        adjusted_sample_size = sample_size\n",
    "    \n",
    "    return int(np.ceil(adjusted_sample_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc33eed4-b2e9-4ab3-94a8-59f04e464c98",
   "metadata": {},
   "source": [
    "### Common Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1dd682b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_urls_from_tlc_page(taxi_page):\n",
    "    \"\"\"\n",
    "    Fetches all URLs from a given webpage.\n",
    "\n",
    "    Args:\n",
    "        taxi_page (str): URL of the webpage to scrape.\n",
    "\n",
    "    Returns:\n",
    "        list: List of all URLs found on the webpage.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Send a GET request to the page\n",
    "        response = requests.get(taxi_page)\n",
    "        response.raise_for_status()  # Raise an HTTPError for bad responses\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise Exception(f\"Failed to access the URL: {taxi_page}. Error: {e}\")\n",
    "    \n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    # Find all anchor tags with href attributes\n",
    "    links = soup.find_all(\"a\", href=True)\n",
    "    \n",
    "    # Extract and return all href attributes\n",
    "    all_urls = [link[\"href\"] for link in links]\n",
    "    \n",
    "    return all_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbd0d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_parquet_urls(all_urls):\n",
    "    parquet_urls = []\n",
    "    for url in all_urls:\n",
    "        # Normalize the URL (strip whitespace, handle cases like trailing slashes)\n",
    "        url = url.strip()\n",
    "        # Use regex to ensure matching even with query parameters\n",
    "        if re.search(r\"\\.parquet(\\?.*)?$\", url):\n",
    "            parquet_urls.append(url)\n",
    "    return parquet_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93daa717",
   "metadata": {},
   "source": [
    "### Process Taxi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f40130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_taxi_month(url: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Downloads, processes, and saves Yellow Taxi dataset for a given month.\n",
    "\n",
    "    Args:\n",
    "        url (str): URL of the Yellow Taxi Parquet file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Sampled and processed DataFrame.\n",
    "    \"\"\"\n",
    "    # Default directory for processed Yellow Taxi data\n",
    "    save_dir = \"processed_data/yellow_taxi\"\n",
    "\n",
    "    # Ensure the save directory exists\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Extract file name and define local path\n",
    "    file_name = url.split(\"/\")[-1]\n",
    "    local_file_path = os.path.join(save_dir, file_name)\n",
    "\n",
    "    # Download the file if not already downloaded\n",
    "    if not os.path.exists(local_file_path):\n",
    "        print(f\"Downloading Yellow Taxi file: {url} ...\")\n",
    "        try:\n",
    "            response = requests.get(url, stream=True)\n",
    "            response.raise_for_status()\n",
    "            with open(local_file_path, \"wb\") as f:\n",
    "                for chunk in response.iter_content(chunk_size=1024 * 1024):  # 1MB chunks\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "            print(f\"File saved to: {local_file_path}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to download {url}: {e}\")\n",
    "            return pd.DataFrame()  # Return an empty DataFrame if download fails\n",
    "    else:\n",
    "        print(f\"Loading file from local storage: {local_file_path}\")\n",
    "\n",
    "    # Load the dataset\n",
    "    try:\n",
    "        data = pd.read_parquet(local_file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading Parquet file {local_file_path}: {e}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if reading fails\n",
    "\n",
    "    # Determine population size\n",
    "    population = len(data)\n",
    "    print(f\"Population size: {population}\")\n",
    "\n",
    "    # Calculate sample size (using p = 0.5 for Yellow Taxi data)\n",
    "    sample_size = calculate_sample_size(population, p = 0.5)\n",
    "    print(f\"Calculated sample size: {sample_size}\")\n",
    "\n",
    "    # Sample the dataset\n",
    "    sampled_data = data.sample(n=sample_size, random_state=42) if population > sample_size else data\n",
    "\n",
    "    # Save the sampled dataset\n",
    "    processed_file_path = os.path.join(save_dir, f\"sampled_{file_name}\")\n",
    "    sampled_data.to_parquet(processed_file_path)\n",
    "    print(f\"Processed file saved to: {processed_file_path}\")\n",
    "\n",
    "    return sampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35c9c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_taxi_data(parquet_urls):\n",
    "    all_taxi_dataframes = []\n",
    "\n",
    "    # filter urls of yellow taxi data\n",
    "    yellow_taxi_pattern = re.compile(r\"yellow_tripdata_(2020-(0[1-9]|1[0-2])|202[1-3]-(0[1-9]|1[0-2])|2024-(0[1-8]))\\.parquet\")\n",
    "    yellow_taxi_urls = [url for url in parquet_urls if yellow_taxi_pattern.search(url)]\n",
    "    \n",
    "    for url in yellow_taxi_urls:\n",
    "        # clean data through function defined before\n",
    "        dataframe = get_and_clean_taxi_month(url)\n",
    "\n",
    "        # solving the problem that dataframes contain different name for airport fee due to uppercase/lowercase difference\n",
    "        if \"Airport_fee\" in list(dataframe):\n",
    "            dataframe.rename(columns={\"Airport_fee\": \"airport_fee\"}, inplace=True)\n",
    "        \n",
    "        all_taxi_dataframes.append(dataframe)\n",
    "        \n",
    "    # create a dataframe combining all taxi data\n",
    "    taxi_data = pd.concat(all_taxi_dataframes)\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "200776ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_taxi_data():\n",
    "    # Applying functions defined to get the taxi data\n",
    "    all_urls = get_all_urls_from_tlc_page(TLC_URL)\n",
    "    all_parquet_urls = filter_parquet_urls(all_urls)\n",
    "    taxi_data = get_and_clean_taxi_data(all_parquet_urls)\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "876bd645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2024-01.parquet\n",
      "Population size: 2964624\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2024-01.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2024-02.parquet\n",
      "Population size: 3007526\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2024-02.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2024-03.parquet\n",
      "Population size: 3582628\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2024-03.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2024-04.parquet\n",
      "Population size: 3514289\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2024-04.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2024-05.parquet\n",
      "Population size: 3723833\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2024-05.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2024-06.parquet\n",
      "Population size: 3539193\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2024-06.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2024-07.parquet\n",
      "Population size: 3076903\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2024-07.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2024-08.parquet\n",
      "Population size: 2979183\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2024-08.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2023-01.parquet\n",
      "Population size: 3066766\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2023-01.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2023-02.parquet\n",
      "Population size: 2913955\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2023-02.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2023-03.parquet\n",
      "Population size: 3403766\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2023-03.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2023-04.parquet\n",
      "Population size: 3288250\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2023-04.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2023-05.parquet\n",
      "Population size: 3513649\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2023-05.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2023-06.parquet\n",
      "Population size: 3307234\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2023-06.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2023-07.parquet\n",
      "Population size: 2907108\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2023-07.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2023-08.parquet\n",
      "Population size: 2824209\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2023-08.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2023-09.parquet\n",
      "Population size: 2846722\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2023-09.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2023-10.parquet\n",
      "Population size: 3522285\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2023-10.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2023-11.parquet\n",
      "Population size: 3339715\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2023-11.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2023-12.parquet\n",
      "Population size: 3376567\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2023-12.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2022-01.parquet\n",
      "Population size: 2463931\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2022-01.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2022-02.parquet\n",
      "Population size: 2979431\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2022-02.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2022-03.parquet\n",
      "Population size: 3627882\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2022-03.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2022-04.parquet\n",
      "Population size: 3599920\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2022-04.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2022-05.parquet\n",
      "Population size: 3588295\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2022-05.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2022-06.parquet\n",
      "Population size: 3558124\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2022-06.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2022-07.parquet\n",
      "Population size: 3174394\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2022-07.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2022-08.parquet\n",
      "Population size: 3152677\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2022-08.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2022-09.parquet\n",
      "Population size: 3183767\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2022-09.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2022-10.parquet\n",
      "Population size: 3675411\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2022-10.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2022-11.parquet\n",
      "Population size: 3252717\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2022-11.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2022-12.parquet\n",
      "Population size: 3399549\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2022-12.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2021-01.parquet\n",
      "Population size: 1369769\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2021-01.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2021-02.parquet\n",
      "Population size: 1371709\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2021-02.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2021-03.parquet\n",
      "Population size: 1925152\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2021-03.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2021-04.parquet\n",
      "Population size: 2171187\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2021-04.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2021-05.parquet\n",
      "Population size: 2507109\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2021-05.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2021-06.parquet\n",
      "Population size: 2834264\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2021-06.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2021-07.parquet\n",
      "Population size: 2821746\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2021-07.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2021-08.parquet\n",
      "Population size: 2788757\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2021-08.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2021-09.parquet\n",
      "Population size: 2963793\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2021-09.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2021-10.parquet\n",
      "Population size: 3463504\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2021-10.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2021-11.parquet\n",
      "Population size: 3472949\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2021-11.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2021-12.parquet\n",
      "Population size: 3214369\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2021-12.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2020-01.parquet\n",
      "Population size: 6405008\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2020-01.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2020-02.parquet\n",
      "Population size: 6299367\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2020-02.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2020-03.parquet\n",
      "Population size: 3007687\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2020-03.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2020-04.parquet\n",
      "Population size: 238073\n",
      "Calculated sample size: 384\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2020-04.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2020-05.parquet\n",
      "Population size: 348415\n",
      "Calculated sample size: 384\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2020-05.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2020-06.parquet\n",
      "Population size: 549797\n",
      "Calculated sample size: 384\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2020-06.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2020-07.parquet\n",
      "Population size: 800412\n",
      "Calculated sample size: 384\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2020-07.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2020-08.parquet\n",
      "Population size: 1007286\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2020-08.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2020-09.parquet\n",
      "Population size: 1341017\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2020-09.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2020-10.parquet\n",
      "Population size: 1681132\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2020-10.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2020-11.parquet\n",
      "Population size: 1509000\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2020-11.parquet\n",
      "Loading file from local storage: processed_data/yellow_taxi/yellow_tripdata_2020-12.parquet\n",
      "Population size: 1461898\n",
      "Calculated sample size: 385\n",
      "Processed file saved to: processed_data/yellow_taxi/sampled_yellow_tripdata_2020-12.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kg/5js8flcn3c138fq2kf35s9vh0000gn/T/ipykernel_70862/3668426633.py:19: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  taxi_data = pd.concat(all_taxi_dataframes)\n"
     ]
    }
   ],
   "source": [
    "taxi_data = get_taxi_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10ebd75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1725696</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-20 13:31:30</td>\n",
       "      <td>2024-01-20 14:03:25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>132</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.27</td>\n",
       "      <td>6.94</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.96</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581136</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-18 21:52:46</td>\n",
       "      <td>2024-01-18 22:03:21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>163</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>13.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.50</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19137</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-01 03:43:58</td>\n",
       "      <td>2024-01-01 03:50:47</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>127</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682810</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-19 22:20:12</td>\n",
       "      <td>2024-01-19 22:50:12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>186</td>\n",
       "      <td>263</td>\n",
       "      <td>1</td>\n",
       "      <td>23.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.95</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511035</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-06 22:41:50</td>\n",
       "      <td>2024-01-06 22:43:24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "1725696         2  2024-01-20 13:31:30   2024-01-20 14:03:25              2.0   \n",
       "1581136         2  2024-01-18 21:52:46   2024-01-18 22:03:21              1.0   \n",
       "19137           2  2024-01-01 03:43:58   2024-01-01 03:50:47              2.0   \n",
       "1682810         1  2024-01-19 22:20:12   2024-01-19 22:50:12              1.0   \n",
       "511035          2  2024-01-06 22:41:50   2024-01-06 22:43:24              1.0   \n",
       "\n",
       "         trip_distance  RatecodeID store_and_fwd_flag  PULocationID  \\\n",
       "1725696          17.14         2.0                  N           132   \n",
       "1581136           2.49         1.0                  N           163   \n",
       "19137             1.84         1.0                  N           127   \n",
       "1682810           3.60         1.0                  N           186   \n",
       "511035            0.04         1.0                  N           238   \n",
       "\n",
       "         DOLocationID  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
       "1725696           233             1         70.0    0.0      0.5        8.27   \n",
       "1581136            75             1         13.5    1.0      0.5        4.00   \n",
       "19137              20             2         10.0    1.0      0.5        0.00   \n",
       "1682810           263             1         23.3    3.5      0.5        5.65   \n",
       "511035            238             2          3.7    1.0      0.5        0.00   \n",
       "\n",
       "         tolls_amount  improvement_surcharge  total_amount  \\\n",
       "1725696          6.94                    1.0         90.96   \n",
       "1581136          0.00                    1.0         22.50   \n",
       "19137            0.00                    1.0         12.50   \n",
       "1682810          0.00                    1.0         33.95   \n",
       "511035           0.00                    1.0          6.20   \n",
       "\n",
       "         congestion_surcharge  airport_fee  \n",
       "1725696                   2.5         1.75  \n",
       "1581136                   2.5         0.00  \n",
       "19137                     0.0         0.00  \n",
       "1682810                   2.5         0.00  \n",
       "511035                    0.0         0.00  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9da7089-3f6b-4f93-a22e-76bf554daca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 21556 entries, 1725696 to 701728\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   VendorID               21556 non-null  int64         \n",
      " 1   tpep_pickup_datetime   21556 non-null  datetime64[us]\n",
      " 2   tpep_dropoff_datetime  21556 non-null  datetime64[us]\n",
      " 3   passenger_count        20381 non-null  float64       \n",
      " 4   trip_distance          21556 non-null  float64       \n",
      " 5   RatecodeID             20381 non-null  float64       \n",
      " 6   store_and_fwd_flag     20381 non-null  object        \n",
      " 7   PULocationID           21556 non-null  int64         \n",
      " 8   DOLocationID           21556 non-null  int64         \n",
      " 9   payment_type           21556 non-null  int64         \n",
      " 10  fare_amount            21556 non-null  float64       \n",
      " 11  extra                  21556 non-null  float64       \n",
      " 12  mta_tax                21556 non-null  float64       \n",
      " 13  tip_amount             21556 non-null  float64       \n",
      " 14  tolls_amount           21556 non-null  float64       \n",
      " 15  improvement_surcharge  21556 non-null  float64       \n",
      " 16  total_amount           21556 non-null  float64       \n",
      " 17  congestion_surcharge   20381 non-null  float64       \n",
      " 18  airport_fee            15054 non-null  float64       \n",
      "dtypes: datetime64[us](2), float64(12), int64(4), object(1)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "taxi_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50c85e25-6416-4c16-b98c-09596cdc6865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21556.000000</td>\n",
       "      <td>21556</td>\n",
       "      <td>21556</td>\n",
       "      <td>20381.000000</td>\n",
       "      <td>21556.000000</td>\n",
       "      <td>20381.000000</td>\n",
       "      <td>21556.000000</td>\n",
       "      <td>21556.000000</td>\n",
       "      <td>21556.000000</td>\n",
       "      <td>21556.000000</td>\n",
       "      <td>21556.000000</td>\n",
       "      <td>21556.000000</td>\n",
       "      <td>21556.000000</td>\n",
       "      <td>21556.000000</td>\n",
       "      <td>21556.000000</td>\n",
       "      <td>21556.000000</td>\n",
       "      <td>20381.000000</td>\n",
       "      <td>15054.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.719197</td>\n",
       "      <td>2022-05-01 19:16:50.909074</td>\n",
       "      <td>2022-05-01 19:33:07.142048</td>\n",
       "      <td>1.399980</td>\n",
       "      <td>3.292046</td>\n",
       "      <td>1.468132</td>\n",
       "      <td>165.086472</td>\n",
       "      <td>161.552282</td>\n",
       "      <td>1.184682</td>\n",
       "      <td>15.582768</td>\n",
       "      <td>1.192449</td>\n",
       "      <td>0.488194</td>\n",
       "      <td>2.692410</td>\n",
       "      <td>0.451578</td>\n",
       "      <td>0.542666</td>\n",
       "      <td>22.609807</td>\n",
       "      <td>2.265958</td>\n",
       "      <td>0.113442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2009-01-01 01:11:17</td>\n",
       "      <td>2009-01-01 01:11:20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-250.000000</td>\n",
       "      <td>-7.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.130000</td>\n",
       "      <td>-34.200000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-251.000000</td>\n",
       "      <td>-2.500000</td>\n",
       "      <td>-1.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2021-03-01 12:26:32.750000</td>\n",
       "      <td>2021-03-01 12:34:07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2022-05-01 13:35:11.500000</td>\n",
       "      <td>2022-05-01 14:01:36.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.700000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>17.020000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2023-07-01 00:03:05</td>\n",
       "      <td>2023-07-01 00:12:55.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.440000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.800000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>2024-08-31 23:00:33</td>\n",
       "      <td>2024-08-31 23:34:12</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>67.900000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>265.000000</td>\n",
       "      <td>265.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>278.800000</td>\n",
       "      <td>11.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>51.150000</td>\n",
       "      <td>57.050000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>289.350000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.493676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.981261</td>\n",
       "      <td>4.272702</td>\n",
       "      <td>6.286294</td>\n",
       "      <td>65.699489</td>\n",
       "      <td>70.905294</td>\n",
       "      <td>0.568066</td>\n",
       "      <td>15.408238</td>\n",
       "      <td>1.511804</td>\n",
       "      <td>0.097580</td>\n",
       "      <td>3.282479</td>\n",
       "      <td>1.909912</td>\n",
       "      <td>0.353155</td>\n",
       "      <td>19.130045</td>\n",
       "      <td>0.780689</td>\n",
       "      <td>0.405524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           VendorID        tpep_pickup_datetime       tpep_dropoff_datetime  \\\n",
       "count  21556.000000                       21556                       21556   \n",
       "mean       1.719197  2022-05-01 19:16:50.909074  2022-05-01 19:33:07.142048   \n",
       "min        1.000000         2009-01-01 01:11:17         2009-01-01 01:11:20   \n",
       "25%        1.000000  2021-03-01 12:26:32.750000         2021-03-01 12:34:07   \n",
       "50%        2.000000  2022-05-01 13:35:11.500000  2022-05-01 14:01:36.500000   \n",
       "75%        2.000000         2023-07-01 00:03:05  2023-07-01 00:12:55.500000   \n",
       "max        6.000000         2024-08-31 23:00:33         2024-08-31 23:34:12   \n",
       "std        0.493676                         NaN                         NaN   \n",
       "\n",
       "       passenger_count  trip_distance    RatecodeID  PULocationID  \\\n",
       "count     20381.000000   21556.000000  20381.000000  21556.000000   \n",
       "mean          1.399980       3.292046      1.468132    165.086472   \n",
       "min           0.000000       0.000000      1.000000      4.000000   \n",
       "25%           1.000000       1.050000      1.000000    132.000000   \n",
       "50%           1.000000       1.800000      1.000000    162.000000   \n",
       "75%           1.000000       3.310000      1.000000    234.000000   \n",
       "max           6.000000      67.900000     99.000000    265.000000   \n",
       "std           0.981261       4.272702      6.286294     65.699489   \n",
       "\n",
       "       DOLocationID  payment_type   fare_amount         extra       mta_tax  \\\n",
       "count  21556.000000  21556.000000  21556.000000  21556.000000  21556.000000   \n",
       "mean     161.552282      1.184682     15.582768      1.192449      0.488194   \n",
       "min        1.000000      0.000000   -250.000000     -7.500000     -0.500000   \n",
       "25%      107.000000      1.000000      7.200000      0.000000      0.500000   \n",
       "50%      162.000000      1.000000     10.700000      0.500000      0.500000   \n",
       "75%      234.000000      1.000000     17.500000      2.500000      0.500000   \n",
       "max      265.000000      4.000000    278.800000     11.750000      0.500000   \n",
       "std       70.905294      0.568066     15.408238      1.511804      0.097580   \n",
       "\n",
       "         tip_amount  tolls_amount  improvement_surcharge  total_amount  \\\n",
       "count  21556.000000  21556.000000           21556.000000  21556.000000   \n",
       "mean       2.692410      0.451578               0.542666     22.609807   \n",
       "min       -0.130000    -34.200000              -1.000000   -251.000000   \n",
       "25%        0.000000      0.000000               0.300000     12.600000   \n",
       "50%        2.150000      0.000000               0.300000     17.020000   \n",
       "75%        3.440000      0.000000               1.000000     24.800000   \n",
       "max       51.150000     57.050000               1.000000    289.350000   \n",
       "std        3.282479      1.909912               0.353155     19.130045   \n",
       "\n",
       "       congestion_surcharge   airport_fee  \n",
       "count          20381.000000  15054.000000  \n",
       "mean               2.265958      0.113442  \n",
       "min               -2.500000     -1.750000  \n",
       "25%                2.500000      0.000000  \n",
       "50%                2.500000      0.000000  \n",
       "75%                2.500000      0.000000  \n",
       "max                2.500000      1.750000  \n",
       "std                0.780689      0.405524  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094b4d6d",
   "metadata": {},
   "source": [
    "### Processing Uber Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "07574983-f41d-4cd6-8f70-489493089b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_uber_month(url):\n",
    "    save_dir = \"processed_data/hvhf\"\n",
    "\n",
    "    # Ensure the save directory exists\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Extract file name and define local path\n",
    "    file_name = url.split(\"/\")[-1]\n",
    "    local_file_path = os.path.join(save_dir, file_name)\n",
    "\n",
    "    # Download the file if not already downloaded\n",
    "    if not os.path.exists(local_file_path):\n",
    "        print(f\"Downloading HVHF file: {url} ...\")\n",
    "        try:\n",
    "            response = requests.get(url, stream=True)\n",
    "            response.raise_for_status()\n",
    "            with open(local_file_path, \"wb\") as f:\n",
    "                for chunk in response.iter_content(chunk_size=1024 * 1024):  # 1MB chunks\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "            print(f\"File saved to: {local_file_path}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to download {url}: {e}\")\n",
    "            return pd.DataFrame()  # Return an empty DataFrame if download fails\n",
    "    else:\n",
    "        print(f\"Loading file from local storage: {local_file_path}\")\n",
    "\n",
    "    # Load the dataset\n",
    "    try:\n",
    "        data = pd.read_parquet(local_file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading Parquet file {local_file_path}: {e}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if reading fails\n",
    "\n",
    "    # Determine population size\n",
    "    population = len(data)\n",
    "    print(f\"Population size: {population}\")\n",
    "\n",
    "    # Calculate sample size (using p = 0.5 for Yellow Taxi data)\n",
    "    sample_size = calculate_sample_size(population, p = 0.4)\n",
    "    print(f\"Calculated sample size: {sample_size}\")\n",
    "\n",
    "    # Sample the dataset\n",
    "    sampled_data = data.sample(n=sample_size, random_state=42) if population > sample_size else data\n",
    "\n",
    "    # Save the sampled dataset\n",
    "    processed_file_path = os.path.join(save_dir, f\"sampled_{file_name}\")\n",
    "    sampled_data.to_parquet(processed_file_path)\n",
    "    print(f\"Processed file saved to: {processed_file_path}\")\n",
    "\n",
    "    return sampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b3d85ff-313c-41a2-9a46-261a9a2bb10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_uber_data(parquet_urls):\n",
    "    all_uber_dataframes = []\n",
    "\n",
    "    # filter urls of hvfhv data\n",
    "    hvfhv_pattern = re.compile(r\"fhvhv_tripdata_(2020-(0[1-9]|1[0-2])|202[1-3]-(0[1-9]|1[0-2])|2024-(0[1-8]))\\.parquet\")\n",
    "    hvfhv_urls = [url for url in parquet_urls if hvfhv_pattern.search(url)]\n",
    "    \n",
    "    for url in hvfhv_urls:\n",
    "        # clean data through function defined before\n",
    "        dataframe = get_and_clean_uber_month(url)\n",
    "        \n",
    "        all_uber_dataframes.append(dataframe)\n",
    "        \n",
    "    # create a dataframe combining all hvfhv data\n",
    "    uber_data = pd.concat(all_uber_dataframes)\n",
    "    return uber_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c58e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_uber_data(uber_data):\n",
    "    uber_data['hvfhs_license_num'] = uber_data['hvfhs_license_num'].astype(str)\n",
    "    \n",
    "    # Filter rows where 'hvfhs_license_num' is 'HV0003' (Uber)\n",
    "    uber_only_data = uber_data[uber_data['hvfhs_license_num'] == 'HV0003'].copy()\n",
    "    return uber_only_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f836f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uber_data():\n",
    "    # Applying functions defined to get uber data\n",
    "    all_urls = get_all_urls_from_tlc_page(TLC_URL)\n",
    "    all_parquet_urls = filter_parquet_urls(all_urls)\n",
    "    u_data = get_and_clean_uber_data(all_parquet_urls)\n",
    "    uber_data = load_and_clean_uber_data(u_data)\n",
    "    return uber_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9c2bd13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2024-01.parquet\n",
      "Population size: 19663930\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2024-01.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2024-02.parquet\n",
      "Population size: 19359148\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2024-02.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2024-03.parquet\n",
      "Population size: 21280788\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2024-03.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2024-04.parquet\n",
      "Population size: 19733038\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2024-04.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2024-05.parquet\n",
      "Population size: 20704538\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2024-05.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2024-06.parquet\n",
      "Population size: 20123226\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2024-06.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2024-07.parquet\n",
      "Population size: 19182934\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2024-07.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2024-08.parquet\n",
      "Population size: 19128392\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2024-08.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2023-01.parquet\n",
      "Population size: 18479031\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2023-01.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2023-02.parquet\n",
      "Population size: 17960971\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2023-02.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2023-03.parquet\n",
      "Population size: 20413539\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2023-03.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2023-04.parquet\n",
      "Population size: 19144903\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2023-04.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2023-05.parquet\n",
      "Population size: 19847676\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2023-05.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2023-06.parquet\n",
      "Population size: 19366619\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2023-06.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2023-07.parquet\n",
      "Population size: 19132131\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2023-07.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2023-08.parquet\n",
      "Population size: 18322150\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2023-08.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2023-09.parquet\n",
      "Population size: 19851123\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2023-09.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2023-10.parquet\n",
      "Population size: 20186330\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2023-10.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2023-11.parquet\n",
      "Population size: 19269250\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2023-11.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2023-12.parquet\n",
      "Population size: 20516297\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2023-12.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2022-01.parquet\n",
      "Population size: 14751591\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2022-01.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2022-02.parquet\n",
      "Population size: 16019283\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2022-02.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2022-03.parquet\n",
      "Population size: 18453548\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2022-03.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2022-04.parquet\n",
      "Population size: 17752561\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2022-04.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2022-05.parquet\n",
      "Population size: 18157335\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2022-05.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2022-06.parquet\n",
      "Population size: 17780075\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2022-06.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2022-07.parquet\n",
      "Population size: 17464619\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2022-07.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2022-08.parquet\n",
      "Population size: 17185687\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2022-08.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2022-09.parquet\n",
      "Population size: 17793551\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2022-09.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2022-10.parquet\n",
      "Population size: 19306090\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2022-10.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2022-11.parquet\n",
      "Population size: 18085896\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2022-11.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2022-12.parquet\n",
      "Population size: 19665847\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2022-12.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2021-01.parquet\n",
      "Population size: 11908468\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2021-01.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2021-02.parquet\n",
      "Population size: 11613942\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2021-02.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2021-03.parquet\n",
      "Population size: 14227393\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2021-03.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2021-04.parquet\n",
      "Population size: 14111371\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2021-04.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2021-05.parquet\n",
      "Population size: 14719171\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2021-05.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2021-06.parquet\n",
      "Population size: 14961892\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2021-06.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2021-07.parquet\n",
      "Population size: 15027174\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2021-07.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2021-08.parquet\n",
      "Population size: 14499696\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2021-08.parquet\n",
      "Loading file from local storage: processed_data/hvhf/fhvhv_tripdata_2021-09.parquet\n",
      "Error reading Parquet file processed_data/hvhf/fhvhv_tripdata_2021-09.parquet: Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "Downloading HVHF file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-10.parquet ...\n",
      "File saved to: processed_data/hvhf/fhvhv_tripdata_2021-10.parquet\n",
      "Population size: 16545356\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2021-10.parquet\n",
      "Downloading HVHF file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-11.parquet ...\n",
      "File saved to: processed_data/hvhf/fhvhv_tripdata_2021-11.parquet\n",
      "Population size: 16041639\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2021-11.parquet\n",
      "Downloading HVHF file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-12.parquet ...\n",
      "File saved to: processed_data/hvhf/fhvhv_tripdata_2021-12.parquet\n",
      "Population size: 16054495\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2021-12.parquet\n",
      "Downloading HVHF file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-01.parquet ...\n",
      "File saved to: processed_data/hvhf/fhvhv_tripdata_2020-01.parquet\n",
      "Population size: 20569368\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2020-01.parquet\n",
      "Downloading HVHF file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-02.parquet ...\n",
      "File saved to: processed_data/hvhf/fhvhv_tripdata_2020-02.parquet\n",
      "Population size: 21725100\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2020-02.parquet\n",
      "Downloading HVHF file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-03.parquet ...\n",
      "File saved to: processed_data/hvhf/fhvhv_tripdata_2020-03.parquet\n",
      "Population size: 13392928\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2020-03.parquet\n",
      "Downloading HVHF file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-04.parquet ...\n",
      "File saved to: processed_data/hvhf/fhvhv_tripdata_2020-04.parquet\n",
      "Population size: 4312909\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2020-04.parquet\n",
      "Downloading HVHF file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-05.parquet ...\n",
      "File saved to: processed_data/hvhf/fhvhv_tripdata_2020-05.parquet\n",
      "Population size: 6089999\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2020-05.parquet\n",
      "Downloading HVHF file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-06.parquet ...\n",
      "File saved to: processed_data/hvhf/fhvhv_tripdata_2020-06.parquet\n",
      "Population size: 7555193\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2020-06.parquet\n",
      "Downloading HVHF file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-07.parquet ...\n",
      "File saved to: processed_data/hvhf/fhvhv_tripdata_2020-07.parquet\n",
      "Population size: 9958454\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2020-07.parquet\n",
      "Downloading HVHF file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-08.parquet ...\n",
      "File saved to: processed_data/hvhf/fhvhv_tripdata_2020-08.parquet\n",
      "Population size: 11096852\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2020-08.parquet\n",
      "Downloading HVHF file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-09.parquet ...\n",
      "File saved to: processed_data/hvhf/fhvhv_tripdata_2020-09.parquet\n",
      "Population size: 12106669\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2020-09.parquet\n",
      "Downloading HVHF file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-10.parquet ...\n",
      "File saved to: processed_data/hvhf/fhvhv_tripdata_2020-10.parquet\n",
      "Population size: 13268411\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2020-10.parquet\n",
      "Downloading HVHF file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-11.parquet ...\n",
      "File saved to: processed_data/hvhf/fhvhv_tripdata_2020-11.parquet\n",
      "Population size: 11596865\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2020-11.parquet\n",
      "Downloading HVHF file: https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-12.parquet ...\n",
      "File saved to: processed_data/hvhf/fhvhv_tripdata_2020-12.parquet\n",
      "Population size: 11637123\n",
      "Calculated sample size: 369\n",
      "Processed file saved to: processed_data/hvhf/sampled_fhvhv_tripdata_2020-12.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kg/5js8flcn3c138fq2kf35s9vh0000gn/T/ipykernel_70862/3445468452.py:15: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  uber_data = pd.concat(all_uber_dataframes)\n"
     ]
    }
   ],
   "source": [
    "uber_data = get_uber_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "339997e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hvfhs_license_num</th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>originating_base_num</th>\n",
       "      <th>request_datetime</th>\n",
       "      <th>on_scene_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>...</th>\n",
       "      <th>sales_tax</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>tips</th>\n",
       "      <th>driver_pay</th>\n",
       "      <th>shared_request_flag</th>\n",
       "      <th>shared_match_flag</th>\n",
       "      <th>access_a_ride_flag</th>\n",
       "      <th>wav_request_flag</th>\n",
       "      <th>wav_match_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15895061</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2024-01-26 07:58:05</td>\n",
       "      <td>2024-01-26 08:06:17</td>\n",
       "      <td>2024-01-26 08:07:17</td>\n",
       "      <td>2024-01-26 08:35:38</td>\n",
       "      <td>85</td>\n",
       "      <td>77</td>\n",
       "      <td>4.29</td>\n",
       "      <td>...</td>\n",
       "      <td>2.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.88</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11113736</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2024-01-19 02:12:56</td>\n",
       "      <td>2024-01-19 02:16:27</td>\n",
       "      <td>2024-01-19 02:17:05</td>\n",
       "      <td>2024-01-19 02:29:12</td>\n",
       "      <td>220</td>\n",
       "      <td>243</td>\n",
       "      <td>2.55</td>\n",
       "      <td>...</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.19</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12716273</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2024-01-21 01:39:37</td>\n",
       "      <td>2024-01-21 01:43:40</td>\n",
       "      <td>2024-01-21 01:44:00</td>\n",
       "      <td>2024-01-21 02:08:30</td>\n",
       "      <td>164</td>\n",
       "      <td>80</td>\n",
       "      <td>6.37</td>\n",
       "      <td>...</td>\n",
       "      <td>2.18</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.01</td>\n",
       "      <td>23.00</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12099486</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2024-01-20 12:56:18</td>\n",
       "      <td>2024-01-20 12:58:28</td>\n",
       "      <td>2024-01-20 12:58:40</td>\n",
       "      <td>2024-01-20 13:15:42</td>\n",
       "      <td>161</td>\n",
       "      <td>246</td>\n",
       "      <td>1.99</td>\n",
       "      <td>...</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.47</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730768</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B03404</td>\n",
       "      <td>B03404</td>\n",
       "      <td>2024-01-02 08:22:37</td>\n",
       "      <td>2024-01-02 08:40:29</td>\n",
       "      <td>2024-01-02 08:40:48</td>\n",
       "      <td>2024-01-02 08:54:28</td>\n",
       "      <td>77</td>\n",
       "      <td>177</td>\n",
       "      <td>2.23</td>\n",
       "      <td>...</td>\n",
       "      <td>1.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.64</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         hvfhs_license_num dispatching_base_num originating_base_num  \\\n",
       "15895061            HV0003               B03404               B03404   \n",
       "11113736            HV0003               B03404               B03404   \n",
       "12716273            HV0003               B03404               B03404   \n",
       "12099486            HV0003               B03404               B03404   \n",
       "730768              HV0003               B03404               B03404   \n",
       "\n",
       "            request_datetime   on_scene_datetime     pickup_datetime  \\\n",
       "15895061 2024-01-26 07:58:05 2024-01-26 08:06:17 2024-01-26 08:07:17   \n",
       "11113736 2024-01-19 02:12:56 2024-01-19 02:16:27 2024-01-19 02:17:05   \n",
       "12716273 2024-01-21 01:39:37 2024-01-21 01:43:40 2024-01-21 01:44:00   \n",
       "12099486 2024-01-20 12:56:18 2024-01-20 12:58:28 2024-01-20 12:58:40   \n",
       "730768   2024-01-02 08:22:37 2024-01-02 08:40:29 2024-01-02 08:40:48   \n",
       "\n",
       "            dropoff_datetime  PULocationID  DOLocationID  trip_miles  ...  \\\n",
       "15895061 2024-01-26 08:35:38            85            77        4.29  ...   \n",
       "11113736 2024-01-19 02:29:12           220           243        2.55  ...   \n",
       "12716273 2024-01-21 02:08:30           164            80        6.37  ...   \n",
       "12099486 2024-01-20 13:15:42           161           246        1.99  ...   \n",
       "730768   2024-01-02 08:54:28            77           177        2.23  ...   \n",
       "\n",
       "          sales_tax  congestion_surcharge  airport_fee  tips  driver_pay  \\\n",
       "15895061       2.44                  0.00          0.0  0.00       24.88   \n",
       "11113736       1.34                  0.00          0.0  0.00       10.19   \n",
       "12716273       2.18                  2.75          0.0  3.01       23.00   \n",
       "12099486       1.68                  2.75          0.0  0.00       12.47   \n",
       "730768         1.43                  0.00          0.0  0.00       10.64   \n",
       "\n",
       "          shared_request_flag  shared_match_flag  access_a_ride_flag  \\\n",
       "15895061                    N                  N                   N   \n",
       "11113736                    N                  N                   N   \n",
       "12716273                    N                  N                   N   \n",
       "12099486                    N                  N                   N   \n",
       "730768                      N                  N                   N   \n",
       "\n",
       "          wav_request_flag wav_match_flag  \n",
       "15895061                 N              N  \n",
       "11113736                 N              N  \n",
       "12716273                 N              N  \n",
       "12099486                 N              N  \n",
       "730768                   N              N  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "74d783db-e527-4847-bf70-2d7428ea3897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 14735 entries, 15895061 to 5156077\n",
      "Data columns (total 24 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   hvfhs_license_num     14735 non-null  object        \n",
      " 1   dispatching_base_num  14735 non-null  object        \n",
      " 2   originating_base_num  14732 non-null  object        \n",
      " 3   request_datetime      14735 non-null  datetime64[us]\n",
      " 4   on_scene_datetime     14735 non-null  datetime64[us]\n",
      " 5   pickup_datetime       14735 non-null  datetime64[us]\n",
      " 6   dropoff_datetime      14735 non-null  datetime64[us]\n",
      " 7   PULocationID          14735 non-null  int64         \n",
      " 8   DOLocationID          14735 non-null  int64         \n",
      " 9   trip_miles            14735 non-null  float64       \n",
      " 10  trip_time             14735 non-null  int64         \n",
      " 11  base_passenger_fare   14735 non-null  float64       \n",
      " 12  tolls                 14735 non-null  float64       \n",
      " 13  bcf                   14735 non-null  float64       \n",
      " 14  sales_tax             14735 non-null  float64       \n",
      " 15  congestion_surcharge  14735 non-null  float64       \n",
      " 16  airport_fee           10782 non-null  float64       \n",
      " 17  tips                  14735 non-null  float64       \n",
      " 18  driver_pay            14735 non-null  float64       \n",
      " 19  shared_request_flag   14735 non-null  object        \n",
      " 20  shared_match_flag     14735 non-null  object        \n",
      " 21  access_a_ride_flag    14735 non-null  object        \n",
      " 22  wav_request_flag      14735 non-null  object        \n",
      " 23  wav_match_flag        14735 non-null  object        \n",
      "dtypes: datetime64[us](4), float64(9), int64(3), object(8)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "uber_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6fddeb14-cd70-4e83-8f93-974642c3bea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request_datetime</th>\n",
       "      <th>on_scene_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>trip_time</th>\n",
       "      <th>base_passenger_fare</th>\n",
       "      <th>tolls</th>\n",
       "      <th>bcf</th>\n",
       "      <th>sales_tax</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>tips</th>\n",
       "      <th>driver_pay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14735</td>\n",
       "      <td>14735</td>\n",
       "      <td>14735</td>\n",
       "      <td>14735</td>\n",
       "      <td>14735.000000</td>\n",
       "      <td>14735.000000</td>\n",
       "      <td>14735.000000</td>\n",
       "      <td>14735.000000</td>\n",
       "      <td>14735.000000</td>\n",
       "      <td>14735.000000</td>\n",
       "      <td>14735.000000</td>\n",
       "      <td>14735.000000</td>\n",
       "      <td>14735.000000</td>\n",
       "      <td>10782.000000</td>\n",
       "      <td>14735.000000</td>\n",
       "      <td>14735.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2022-05-10 11:24:19.137292</td>\n",
       "      <td>2022-05-10 11:27:55.282049</td>\n",
       "      <td>2022-05-10 11:29:03.377264</td>\n",
       "      <td>2022-05-10 11:47:31.430879</td>\n",
       "      <td>137.995521</td>\n",
       "      <td>141.152969</td>\n",
       "      <td>4.850448</td>\n",
       "      <td>1108.307567</td>\n",
       "      <td>22.545591</td>\n",
       "      <td>1.039011</td>\n",
       "      <td>0.668585</td>\n",
       "      <td>1.893382</td>\n",
       "      <td>1.018409</td>\n",
       "      <td>0.190248</td>\n",
       "      <td>0.905722</td>\n",
       "      <td>18.016880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2020-01-01 02:45:20</td>\n",
       "      <td>2020-01-01 02:48:30</td>\n",
       "      <td>2020-01-01 02:50:21</td>\n",
       "      <td>2020-01-01 03:12:01</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>-24.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2021-02-25 15:22:55</td>\n",
       "      <td>2021-02-25 15:26:33</td>\n",
       "      <td>2021-02-25 15:27:01</td>\n",
       "      <td>2021-02-25 15:50:44</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>10.660000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2022-05-21 20:05:55</td>\n",
       "      <td>2022-05-21 20:18:20</td>\n",
       "      <td>2022-05-21 20:19:41</td>\n",
       "      <td>2022-05-21 20:45:14</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>2.930000</td>\n",
       "      <td>904.000000</td>\n",
       "      <td>17.090000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.440000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2023-07-11 22:14:41</td>\n",
       "      <td>2023-07-11 22:17:23.500000</td>\n",
       "      <td>2023-07-11 22:19:03.500000</td>\n",
       "      <td>2023-07-11 22:44:39</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>5.960000</td>\n",
       "      <td>1417.000000</td>\n",
       "      <td>27.540000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>2.370000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024-08-31 21:35:47</td>\n",
       "      <td>2024-08-31 21:36:33</td>\n",
       "      <td>2024-08-31 21:37:05</td>\n",
       "      <td>2024-08-31 21:57:29</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>265.000000</td>\n",
       "      <td>123.170000</td>\n",
       "      <td>9710.000000</td>\n",
       "      <td>347.900000</td>\n",
       "      <td>43.890000</td>\n",
       "      <td>10.440000</td>\n",
       "      <td>30.880000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>58.790000</td>\n",
       "      <td>261.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.543186</td>\n",
       "      <td>78.083027</td>\n",
       "      <td>5.684854</td>\n",
       "      <td>783.237487</td>\n",
       "      <td>19.468835</td>\n",
       "      <td>3.812899</td>\n",
       "      <td>0.627119</td>\n",
       "      <td>1.600158</td>\n",
       "      <td>1.323663</td>\n",
       "      <td>0.666302</td>\n",
       "      <td>2.920196</td>\n",
       "      <td>14.865439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 request_datetime           on_scene_datetime  \\\n",
       "count                       14735                       14735   \n",
       "mean   2022-05-10 11:24:19.137292  2022-05-10 11:27:55.282049   \n",
       "min           2020-01-01 02:45:20         2020-01-01 02:48:30   \n",
       "25%           2021-02-25 15:22:55         2021-02-25 15:26:33   \n",
       "50%           2022-05-21 20:05:55         2022-05-21 20:18:20   \n",
       "75%           2023-07-11 22:14:41  2023-07-11 22:17:23.500000   \n",
       "max           2024-08-31 21:35:47         2024-08-31 21:36:33   \n",
       "std                           NaN                         NaN   \n",
       "\n",
       "                  pickup_datetime            dropoff_datetime  PULocationID  \\\n",
       "count                       14735                       14735  14735.000000   \n",
       "mean   2022-05-10 11:29:03.377264  2022-05-10 11:47:31.430879    137.995521   \n",
       "min           2020-01-01 02:50:21         2020-01-01 03:12:01      3.000000   \n",
       "25%           2021-02-25 15:27:01         2021-02-25 15:50:44     74.000000   \n",
       "50%           2022-05-21 20:19:41         2022-05-21 20:45:14    140.000000   \n",
       "75%    2023-07-11 22:19:03.500000         2023-07-11 22:44:39    211.000000   \n",
       "max           2024-08-31 21:37:05         2024-08-31 21:57:29    263.000000   \n",
       "std                           NaN                         NaN     75.543186   \n",
       "\n",
       "       DOLocationID    trip_miles     trip_time  base_passenger_fare  \\\n",
       "count  14735.000000  14735.000000  14735.000000         14735.000000   \n",
       "mean     141.152969      4.850448   1108.307567            22.545591   \n",
       "min        1.000000      0.000000     47.000000           -24.900000   \n",
       "25%       74.000000      1.580000    568.000000            10.660000   \n",
       "50%      141.000000      2.930000    904.000000            17.090000   \n",
       "75%      216.000000      5.960000   1417.000000            27.540000   \n",
       "max      265.000000    123.170000   9710.000000           347.900000   \n",
       "std       78.083027      5.684854    783.237487            19.468835   \n",
       "\n",
       "              tolls           bcf     sales_tax  congestion_surcharge  \\\n",
       "count  14735.000000  14735.000000  14735.000000          14735.000000   \n",
       "mean       1.039011      0.668585      1.893382              1.018409   \n",
       "min        0.000000      0.000000      0.000000              0.000000   \n",
       "25%        0.000000      0.290000      0.890000              0.000000   \n",
       "50%        0.000000      0.480000      1.440000              0.000000   \n",
       "75%        0.000000      0.810000      2.370000              2.750000   \n",
       "max       43.890000     10.440000     30.880000              2.750000   \n",
       "std        3.812899      0.627119      1.600158              1.323663   \n",
       "\n",
       "        airport_fee          tips    driver_pay  \n",
       "count  10782.000000  14735.000000  14735.000000  \n",
       "mean       0.190248      0.905722     18.016880  \n",
       "min        0.000000      0.000000      0.000000  \n",
       "25%        0.000000      0.000000      8.460000  \n",
       "50%        0.000000      0.000000     13.730000  \n",
       "75%        0.000000      0.000000     22.470000  \n",
       "max        5.000000     58.790000    261.440000  \n",
       "std        0.666302      2.920196     14.865439  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a15cbb",
   "metadata": {},
   "source": [
    "### Processing Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "0ec5370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_weather_csvs(directory):\n",
    "    # reading all csv files in the directory\n",
    "    files = glob.glob(os.path.join(directory,'*.csv'))\n",
    "    \n",
    "    csv_files =[]\n",
    "    for file in files:\n",
    "        # for each csv file, create a dataframe containing the data\n",
    "        df = pd.read_csv(file, low_memory=False)\n",
    "        \n",
    "        csv_files.append(df)\n",
    "    return csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "76e864ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_hourly(csv_file):\n",
    "    # find all column names in the data\n",
    "    column_names = list(csv_file)\n",
    "    # finding all column names containing 'Hourly', which refer to the hourly data\n",
    "    keys = [name for name in column_names if \"Hourly\" in name]\\\n",
    "    # get the name of columns needed for hourly data\n",
    "    columns = [\"DATE\"] + keys\n",
    "    # create a dataframe containing the columns for hourly data\n",
    "    hourly_data = csv_file[columns]\n",
    "    # filter out non-hourly rows in the dataframe\n",
    "    hourly_data = hourly_data[hourly_data[\"HourlyAltimeterSetting\"].notna()]\n",
    "    return hourly_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "0687581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_daily(csv_file):\n",
    "    # find all column names in the data\n",
    "    column_names = list(csv_file)\n",
    "    # finding all column names containing 'Daily', which refer to the daily data\n",
    "    keys = [name for name in column_names if \"Daily\" in name]\n",
    "    # get the name of columns needed for daily data\n",
    "    columns = [\"DATE\"] + keys\n",
    "    # create a dataframe containing the columns for daily data\n",
    "    daily_data = csv_file[columns]\n",
    "    # filter out non-daily rows in the dataframe\n",
    "    daily_data = daily_data[daily_data[\"DailyAverageDewPointTemperature\"].notna()]\n",
    "    return daily_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "3ef8945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_weather_data():\n",
    "    # get the dataframes of the csv files for weather data\n",
    "    weather_csv_files = get_all_weather_csvs(WEATHER_CSV_DIR)\n",
    "    \n",
    "    hourly_dataframes = []\n",
    "    daily_dataframes = []\n",
    "        \n",
    "    for csv_file in weather_csv_files:\n",
    "        # for each csv_file's data, clean and get the hourly and daily dataframes\n",
    "        hourly_dataframe = clean_month_weather_data_hourly(csv_file)\n",
    "        daily_dataframe = clean_month_weather_data_daily(csv_file)\n",
    "        hourly_dataframes.append(hourly_dataframe)\n",
    "        daily_dataframes.append(daily_dataframe)\n",
    "        \n",
    "    # create two dataframes containing the concatnetion of hourly & daily data respectively\n",
    "    hourly_data = pd.concat(hourly_dataframes)\n",
    "    daily_data = pd.concat(daily_dataframes)\n",
    "\n",
    "    # create hourly_range\n",
    "    hourly_range = pd.date_range(start=\"2023-09-25 00:00:00\", end=\"2023-10-03 23:59:59\", freq=\"1H\")\n",
    "    hourly_range_df = pd.DataFrame(hourly_range, columns=[\"hour\"])\n",
    "    hourly_range_df[\"hour\"] = hourly_range_df[\"hour\"].astype(str)\n",
    "    hourly_range_df.to_sql(\"hourly_range\", con=engine, if_exists=\"replace\", index=False) \n",
    "    \n",
    "    return hourly_data, daily_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "f7cd53a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kg/5js8flcn3c138fq2kf35s9vh0000gn/T/ipykernel_70862/4077312797.py:20: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  hourly_range = pd.date_range(start=\"2023-09-25 00:00:00\", end=\"2023-10-03 23:59:59\", freq=\"1H\")\n"
     ]
    }
   ],
   "source": [
    "hourly_weather_data, daily_weather_data = load_and_clean_weather_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "48216557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>HourlyAltimeterSetting</th>\n",
       "      <th>HourlyDewPointTemperature</th>\n",
       "      <th>HourlyDryBulbTemperature</th>\n",
       "      <th>HourlyPrecipitation</th>\n",
       "      <th>HourlyPresentWeatherType</th>\n",
       "      <th>HourlyPressureChange</th>\n",
       "      <th>HourlyPressureTendency</th>\n",
       "      <th>HourlyRelativeHumidity</th>\n",
       "      <th>HourlySkyConditions</th>\n",
       "      <th>HourlySeaLevelPressure</th>\n",
       "      <th>HourlyStationPressure</th>\n",
       "      <th>HourlyVisibility</th>\n",
       "      <th>HourlyWetBulbTemperature</th>\n",
       "      <th>HourlyWindDirection</th>\n",
       "      <th>HourlyWindGustSpeed</th>\n",
       "      <th>HourlyWindSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01T00:51:00</td>\n",
       "      <td>29.66</td>\n",
       "      <td>26</td>\n",
       "      <td>40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>BKN:07 80 OVC:08 100</td>\n",
       "      <td>29.64</td>\n",
       "      <td>29.49</td>\n",
       "      <td>10.00</td>\n",
       "      <td>35.0</td>\n",
       "      <td>VRB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01T01:51:00</td>\n",
       "      <td>29.67</td>\n",
       "      <td>27</td>\n",
       "      <td>39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.0</td>\n",
       "      <td>BKN:07 70 OVC:08 100</td>\n",
       "      <td>29.65</td>\n",
       "      <td>29.50</td>\n",
       "      <td>10.00</td>\n",
       "      <td>34.0</td>\n",
       "      <td>280</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01T02:51:00</td>\n",
       "      <td>29.68</td>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>FEW:02 70 OVC:08 90</td>\n",
       "      <td>29.66</td>\n",
       "      <td>29.51</td>\n",
       "      <td>10.00</td>\n",
       "      <td>34.0</td>\n",
       "      <td>260</td>\n",
       "      <td>23.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01T03:51:00</td>\n",
       "      <td>29.70</td>\n",
       "      <td>24</td>\n",
       "      <td>39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>OVC:08 75</td>\n",
       "      <td>29.67</td>\n",
       "      <td>29.53</td>\n",
       "      <td>10.00</td>\n",
       "      <td>33.0</td>\n",
       "      <td>250</td>\n",
       "      <td>23.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01T04:51:00</td>\n",
       "      <td>29.70</td>\n",
       "      <td>23</td>\n",
       "      <td>38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.0</td>\n",
       "      <td>OVC:08 65</td>\n",
       "      <td>29.67</td>\n",
       "      <td>29.53</td>\n",
       "      <td>10.00</td>\n",
       "      <td>32.0</td>\n",
       "      <td>VRB</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  DATE HourlyAltimeterSetting HourlyDewPointTemperature  \\\n",
       "0  2020-01-01T00:51:00                  29.66                        26   \n",
       "1  2020-01-01T01:51:00                  29.67                        27   \n",
       "2  2020-01-01T02:51:00                  29.68                        26   \n",
       "3  2020-01-01T03:51:00                  29.70                        24   \n",
       "4  2020-01-01T04:51:00                  29.70                        23   \n",
       "\n",
       "  HourlyDryBulbTemperature HourlyPrecipitation HourlyPresentWeatherType  \\\n",
       "0                       40                0.00                      NaN   \n",
       "1                       39                0.00                      NaN   \n",
       "2                       39                0.00                      NaN   \n",
       "3                       39                0.00                      NaN   \n",
       "4                       38                0.00                      NaN   \n",
       "\n",
       "  HourlyPressureChange  HourlyPressureTendency HourlyRelativeHumidity  \\\n",
       "0                -0.01                     3.0                   58.0   \n",
       "1                  NaN                     NaN                   61.0   \n",
       "2                  NaN                     NaN                   60.0   \n",
       "3                -0.03                     3.0                   55.0   \n",
       "4                  NaN                     NaN                   55.0   \n",
       "\n",
       "    HourlySkyConditions HourlySeaLevelPressure HourlyStationPressure  \\\n",
       "0  BKN:07 80 OVC:08 100                  29.64                 29.49   \n",
       "1  BKN:07 70 OVC:08 100                  29.65                 29.50   \n",
       "2   FEW:02 70 OVC:08 90                  29.66                 29.51   \n",
       "3             OVC:08 75                  29.67                 29.53   \n",
       "4             OVC:08 65                  29.67                 29.53   \n",
       "\n",
       "  HourlyVisibility HourlyWetBulbTemperature HourlyWindDirection  \\\n",
       "0            10.00                     35.0                 VRB   \n",
       "1            10.00                     34.0                 280   \n",
       "2            10.00                     34.0                 260   \n",
       "3            10.00                     33.0                 250   \n",
       "4            10.00                     32.0                 VRB   \n",
       "\n",
       "   HourlyWindGustSpeed  HourlyWindSpeed  \n",
       "0                  NaN              8.0  \n",
       "1                 17.0              8.0  \n",
       "2                 23.0             14.0  \n",
       "3                 23.0             11.0  \n",
       "4                 20.0              6.0  "
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "935261b7-ae23-427c-97ff-ea31aa4e44c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 54185 entries, 0 to 11636\n",
      "Data columns (total 17 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   DATE                       54185 non-null  object \n",
      " 1   HourlyAltimeterSetting     54185 non-null  object \n",
      " 2   HourlyDewPointTemperature  54139 non-null  object \n",
      " 3   HourlyDryBulbTemperature   54179 non-null  object \n",
      " 4   HourlyPrecipitation        47495 non-null  object \n",
      " 5   HourlyPresentWeatherType   13987 non-null  object \n",
      " 6   HourlyPressureChange       13968 non-null  object \n",
      " 7   HourlyPressureTendency     13968 non-null  float64\n",
      " 8   HourlyRelativeHumidity     54139 non-null  object \n",
      " 9   HourlySkyConditions        53612 non-null  object \n",
      " 10  HourlySeaLevelPressure     42023 non-null  object \n",
      " 11  HourlyStationPressure      53893 non-null  object \n",
      " 12  HourlyVisibility           54102 non-null  object \n",
      " 13  HourlyWetBulbTemperature   53847 non-null  object \n",
      " 14  HourlyWindDirection        49590 non-null  object \n",
      " 15  HourlyWindGustSpeed        8342 non-null   float64\n",
      " 16  HourlyWindSpeed            49592 non-null  float64\n",
      "dtypes: float64(3), object(14)\n",
      "memory usage: 7.4+ MB\n"
     ]
    }
   ],
   "source": [
    "hourly_weather_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "a7dcb502-d1d1-447d-aa68-11bff0dc53b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HourlyPressureTendency</th>\n",
       "      <th>HourlyWindGustSpeed</th>\n",
       "      <th>HourlyWindSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13968.000000</td>\n",
       "      <td>8342.000000</td>\n",
       "      <td>49592.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.295604</td>\n",
       "      <td>21.579837</td>\n",
       "      <td>5.125302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.791384</td>\n",
       "      <td>4.653003</td>\n",
       "      <td>14.662725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>2237.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       HourlyPressureTendency  HourlyWindGustSpeed  HourlyWindSpeed\n",
       "count            13968.000000          8342.000000     49592.000000\n",
       "mean                 4.295604            21.579837         5.125302\n",
       "std                  2.791384             4.653003        14.662725\n",
       "min                  0.000000            16.000000         0.000000\n",
       "25%                  1.000000            18.000000         3.000000\n",
       "50%                  3.000000            21.000000         5.000000\n",
       "75%                  7.000000            24.000000         7.000000\n",
       "max                  9.000000            51.000000      2237.000000"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_weather_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "4cb386ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>DailyAverageDewPointTemperature</th>\n",
       "      <th>DailyAverageDryBulbTemperature</th>\n",
       "      <th>DailyAverageRelativeHumidity</th>\n",
       "      <th>DailyAverageSeaLevelPressure</th>\n",
       "      <th>DailyAverageStationPressure</th>\n",
       "      <th>DailyAverageWetBulbTemperature</th>\n",
       "      <th>DailyAverageWindSpeed</th>\n",
       "      <th>DailyCoolingDegreeDays</th>\n",
       "      <th>DailyDepartureFromNormalAverageTemperature</th>\n",
       "      <th>...</th>\n",
       "      <th>DailyMaximumDryBulbTemperature</th>\n",
       "      <th>DailyMinimumDryBulbTemperature</th>\n",
       "      <th>DailyPeakWindDirection</th>\n",
       "      <th>DailyPeakWindSpeed</th>\n",
       "      <th>DailyPrecipitation</th>\n",
       "      <th>DailySnowDepth</th>\n",
       "      <th>DailySnowfall</th>\n",
       "      <th>DailySustainedWindDirection</th>\n",
       "      <th>DailySustainedWindSpeed</th>\n",
       "      <th>DailyWeather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2020-01-01T23:59:00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>29.76</td>\n",
       "      <td>29.62</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2020-01-02T23:59:00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>29.91</td>\n",
       "      <td>29.77</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>...</td>\n",
       "      <td>49.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2020-01-03T23:59:00</td>\n",
       "      <td>41.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>29.81</td>\n",
       "      <td>29.67</td>\n",
       "      <td>44.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>...</td>\n",
       "      <td>49.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>RA BR HZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2020-01-04T23:59:00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>29.62</td>\n",
       "      <td>29.49</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>RA FG BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2020-01-05T23:59:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>29.84</td>\n",
       "      <td>29.69</td>\n",
       "      <td>32.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>T</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    DATE  DailyAverageDewPointTemperature  \\\n",
       "24   2020-01-01T23:59:00                             21.0   \n",
       "49   2020-01-02T23:59:00                             25.0   \n",
       "86   2020-01-03T23:59:00                             41.0   \n",
       "144  2020-01-04T23:59:00                             45.0   \n",
       "169  2020-01-05T23:59:00                             20.0   \n",
       "\n",
       "     DailyAverageDryBulbTemperature  DailyAverageRelativeHumidity  \\\n",
       "24                             38.0                          52.0   \n",
       "49                             41.0                          52.0   \n",
       "86                             47.0                          82.0   \n",
       "144                            46.0                          90.0   \n",
       "169                            39.0                          48.0   \n",
       "\n",
       "     DailyAverageSeaLevelPressure  DailyAverageStationPressure  \\\n",
       "24                          29.76                        29.62   \n",
       "49                          29.91                        29.77   \n",
       "86                          29.81                        29.67   \n",
       "144                         29.62                        29.49   \n",
       "169                         29.84                        29.69   \n",
       "\n",
       "     DailyAverageWetBulbTemperature  DailyAverageWindSpeed  \\\n",
       "24                             32.0                    8.6   \n",
       "49                             36.0                    5.4   \n",
       "86                             44.0                    3.4   \n",
       "144                            46.0                    4.4   \n",
       "169                            32.0                   11.3   \n",
       "\n",
       "     DailyCoolingDegreeDays  DailyDepartureFromNormalAverageTemperature  ...  \\\n",
       "24                      0.0                                         4.6  ...   \n",
       "49                      0.0                                         7.7  ...   \n",
       "86                      0.0                                        13.9  ...   \n",
       "144                     0.0                                        13.0  ...   \n",
       "169                     0.0                                         6.1  ...   \n",
       "\n",
       "     DailyMaximumDryBulbTemperature  DailyMinimumDryBulbTemperature  \\\n",
       "24                             41.0                            34.0   \n",
       "49                             49.0                            33.0   \n",
       "86                             49.0                            44.0   \n",
       "144                            51.0                            41.0   \n",
       "169                            42.0                            35.0   \n",
       "\n",
       "     DailyPeakWindDirection DailyPeakWindSpeed DailyPrecipitation  \\\n",
       "24                    260.0               29.0               0.00   \n",
       "49                    220.0               22.0               0.00   \n",
       "86                    230.0               15.0               0.15   \n",
       "144                   330.0               24.0               0.27   \n",
       "169                   300.0               43.0                  T   \n",
       "\n",
       "    DailySnowDepth DailySnowfall DailySustainedWindDirection  \\\n",
       "24             0.0           0.0                       270.0   \n",
       "49             0.0           0.0                       230.0   \n",
       "86             0.0           0.0                       250.0   \n",
       "144            0.0           0.0                       300.0   \n",
       "169            0.0           0.0                       300.0   \n",
       "\n",
       "    DailySustainedWindSpeed DailyWeather  \n",
       "24                     17.0          NaN  \n",
       "49                     13.0          NaN  \n",
       "86                     10.0     RA BR HZ  \n",
       "144                    15.0     RA FG BR  \n",
       "169                    25.0           RA  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "f090eb94-a5b0-4d93-bf82-a596d2521b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1632 entries, 24 to 11637\n",
      "Data columns (total 21 columns):\n",
      " #   Column                                      Non-Null Count  Dtype  \n",
      "---  ------                                      --------------  -----  \n",
      " 0   DATE                                        1632 non-null   object \n",
      " 1   DailyAverageDewPointTemperature             1632 non-null   float64\n",
      " 2   DailyAverageDryBulbTemperature              1632 non-null   float64\n",
      " 3   DailyAverageRelativeHumidity                1632 non-null   float64\n",
      " 4   DailyAverageSeaLevelPressure                1631 non-null   float64\n",
      " 5   DailyAverageStationPressure                 1632 non-null   float64\n",
      " 6   DailyAverageWetBulbTemperature              1632 non-null   float64\n",
      " 7   DailyAverageWindSpeed                       1574 non-null   float64\n",
      " 8   DailyCoolingDegreeDays                      1632 non-null   float64\n",
      " 9   DailyDepartureFromNormalAverageTemperature  1632 non-null   float64\n",
      " 10  DailyHeatingDegreeDays                      1632 non-null   float64\n",
      " 11  DailyMaximumDryBulbTemperature              1632 non-null   float64\n",
      " 12  DailyMinimumDryBulbTemperature              1632 non-null   float64\n",
      " 13  DailyPeakWindDirection                      1571 non-null   object \n",
      " 14  DailyPeakWindSpeed                          1627 non-null   object \n",
      " 15  DailyPrecipitation                          1632 non-null   object \n",
      " 16  DailySnowDepth                              1632 non-null   object \n",
      " 17  DailySnowfall                               1632 non-null   object \n",
      " 18  DailySustainedWindDirection                 1579 non-null   object \n",
      " 19  DailySustainedWindSpeed                     1632 non-null   object \n",
      " 20  DailyWeather                                787 non-null    object \n",
      "dtypes: float64(12), object(9)\n",
      "memory usage: 280.5+ KB\n"
     ]
    }
   ],
   "source": [
    "daily_weather_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "8c074aa3-a5f2-4586-8748-411e1e6c11da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DailyAverageDewPointTemperature</th>\n",
       "      <th>DailyAverageDryBulbTemperature</th>\n",
       "      <th>DailyAverageRelativeHumidity</th>\n",
       "      <th>DailyAverageSeaLevelPressure</th>\n",
       "      <th>DailyAverageStationPressure</th>\n",
       "      <th>DailyAverageWetBulbTemperature</th>\n",
       "      <th>DailyAverageWindSpeed</th>\n",
       "      <th>DailyCoolingDegreeDays</th>\n",
       "      <th>DailyDepartureFromNormalAverageTemperature</th>\n",
       "      <th>DailyHeatingDegreeDays</th>\n",
       "      <th>DailyMaximumDryBulbTemperature</th>\n",
       "      <th>DailyMinimumDryBulbTemperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1632.000000</td>\n",
       "      <td>1632.000000</td>\n",
       "      <td>1632.000000</td>\n",
       "      <td>1631.000000</td>\n",
       "      <td>1632.000000</td>\n",
       "      <td>1632.000000</td>\n",
       "      <td>1574.000000</td>\n",
       "      <td>1632.000000</td>\n",
       "      <td>1632.000000</td>\n",
       "      <td>1632.000000</td>\n",
       "      <td>1632.000000</td>\n",
       "      <td>1632.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>42.547794</td>\n",
       "      <td>57.700980</td>\n",
       "      <td>61.020221</td>\n",
       "      <td>30.010846</td>\n",
       "      <td>29.863964</td>\n",
       "      <td>50.221814</td>\n",
       "      <td>5.048602</td>\n",
       "      <td>3.759191</td>\n",
       "      <td>2.554596</td>\n",
       "      <td>11.058211</td>\n",
       "      <td>64.518382</td>\n",
       "      <td>50.390319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18.201816</td>\n",
       "      <td>16.241926</td>\n",
       "      <td>15.695804</td>\n",
       "      <td>0.213623</td>\n",
       "      <td>0.214455</td>\n",
       "      <td>14.995885</td>\n",
       "      <td>2.360532</td>\n",
       "      <td>5.885186</td>\n",
       "      <td>6.896218</td>\n",
       "      <td>12.081967</td>\n",
       "      <td>17.109046</td>\n",
       "      <td>15.759504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-7.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>29.220000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-24.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>29.875000</td>\n",
       "      <td>29.730000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>29.850000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>65.500000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>30.150000</td>\n",
       "      <td>30.002500</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>65.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>74.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>30.660000</td>\n",
       "      <td>30.510000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>28.800000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>81.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DailyAverageDewPointTemperature  DailyAverageDryBulbTemperature  \\\n",
       "count                      1632.000000                     1632.000000   \n",
       "mean                         42.547794                       57.700980   \n",
       "std                          18.201816                       16.241926   \n",
       "min                          -7.000000                       11.000000   \n",
       "25%                          28.000000                       45.000000   \n",
       "50%                          43.000000                       58.000000   \n",
       "75%                          58.000000                       72.000000   \n",
       "max                          74.000000                       88.000000   \n",
       "\n",
       "       DailyAverageRelativeHumidity  DailyAverageSeaLevelPressure  \\\n",
       "count                   1632.000000                   1631.000000   \n",
       "mean                      61.020221                     30.010846   \n",
       "std                       15.695804                      0.213623   \n",
       "min                       19.000000                     29.220000   \n",
       "25%                       49.000000                     29.875000   \n",
       "50%                       61.000000                     30.000000   \n",
       "75%                       72.000000                     30.150000   \n",
       "max                       95.000000                     30.660000   \n",
       "\n",
       "       DailyAverageStationPressure  DailyAverageWetBulbTemperature  \\\n",
       "count                  1632.000000                     1632.000000   \n",
       "mean                     29.863964                       50.221814   \n",
       "std                       0.214455                       14.995885   \n",
       "min                      29.000000                        8.000000   \n",
       "25%                      29.730000                       38.000000   \n",
       "50%                      29.850000                       50.000000   \n",
       "75%                      30.002500                       63.000000   \n",
       "max                      30.510000                       76.000000   \n",
       "\n",
       "       DailyAverageWindSpeed  DailyCoolingDegreeDays  \\\n",
       "count            1574.000000             1632.000000   \n",
       "mean                5.048602                3.759191   \n",
       "std                 2.360532                5.885186   \n",
       "min                 0.600000                0.000000   \n",
       "25%                 3.200000                0.000000   \n",
       "50%                 4.700000                0.000000   \n",
       "75%                 6.500000                7.000000   \n",
       "max                14.200000               23.000000   \n",
       "\n",
       "       DailyDepartureFromNormalAverageTemperature  DailyHeatingDegreeDays  \\\n",
       "count                                 1632.000000             1632.000000   \n",
       "mean                                     2.554596               11.058211   \n",
       "std                                      6.896218               12.081967   \n",
       "min                                    -24.200000                0.000000   \n",
       "25%                                     -2.000000                0.000000   \n",
       "50%                                      2.200000                7.000000   \n",
       "75%                                      7.000000               20.000000   \n",
       "max                                     28.800000               54.000000   \n",
       "\n",
       "       DailyMaximumDryBulbTemperature  DailyMinimumDryBulbTemperature  \n",
       "count                     1632.000000                     1632.000000  \n",
       "mean                        64.518382                       50.390319  \n",
       "std                         17.109046                       15.759504  \n",
       "min                         15.000000                        3.000000  \n",
       "25%                         50.000000                       38.000000  \n",
       "50%                         65.500000                       50.000000  \n",
       "75%                         79.000000                       65.000000  \n",
       "max                         98.000000                       81.000000  "
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd101f11",
   "metadata": {},
   "source": [
    "## Part 2: Storing Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "f3529cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "d2bea0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using SQL (as opposed to SQLAlchemy), define the commands \n",
    "# to create your 4 tables/dataframes\n",
    "HOURLY_WEATHER_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS hourly_weather (\n",
    "    date_time TEXT PRIMARY KEY,\n",
    "    temperature FLOAT,\n",
    "    precipitation FLOAT,\n",
    "    wind_speed FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "DAILY_WEATHER_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS daily_weather (\n",
    "    date TEXT PRIMARY KEY,\n",
    "    avg_temperature FLOAT,\n",
    "    total_precipitation FLOAT,\n",
    "    total_snowfall FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "TAXI_TRIPS_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS taxi_trips (\n",
    "    trip_id INTEGER PRIMARY KEY,\n",
    "    pickup_datetime TEXT,\n",
    "    dropoff_datetime TEXT,\n",
    "    trip_distance FLOAT,\n",
    "    fare_amount FLOAT,\n",
    "    tip_amount FLOAT,\n",
    "    total_amount FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "UBER_TRIPS_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS uber_trips (\n",
    "    trip_id INTEGER PRIMARY KEY,\n",
    "    pickup_datetime TEXT,\n",
    "    dropoff_datetime TEXT,\n",
    "FLOAT    trip_distance FLOAT,\n",
    "    fare_amount FLOAT,\n",
    "    tip_amount FLOAT,\n",
    "    total_amount FLOAT\n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "5f41e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create that required schema.sql file\n",
    "with open(DATABASE_SCHEMA_FILE, \"w\") as f:\n",
    "    f.write(HOURLY_WEATHER_SCHEMA)\n",
    "    f.write(DAILY_WEATHER_SCHEMA)\n",
    "    f.write(TAXI_TRIPS_SCHEMA)\n",
    "    f.write(UBER_TRIPS_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "02eccdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tables with the schema files\n",
    "with engine.connect() as connection:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "f407d6e2-03f7-4a3c-9468-d55f0aaa2a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['daily_weather', 'hourly_range', 'hourly_weather', 'taxi_trips', 'uber_trips']\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import inspect\n",
    "\n",
    "inspector = inspect(engine)\n",
    "print(inspector.get_table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "1ff24bd9-da92-4c80-872b-3aa7da4ef096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
      "       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
      "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
      "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
      "       'total_amount', 'congestion_surcharge', 'airport_fee'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(taxi_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "f0303a08-7535-4bc5-8ab8-dc5534a83705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['hvfhs_license_num', 'dispatching_base_num', 'originating_base_num',\n",
      "       'request_datetime', 'on_scene_datetime', 'pickup_datetime',\n",
      "       'dropoff_datetime', 'PULocationID', 'DOLocationID', 'trip_miles',\n",
      "       'trip_time', 'base_passenger_fare', 'tolls', 'bcf', 'sales_tax',\n",
      "       'congestion_surcharge', 'airport_fee', 'tips', 'driver_pay',\n",
      "       'shared_request_flag', 'shared_match_flag', 'access_a_ride_flag',\n",
      "       'wav_request_flag', 'wav_match_flag'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(uber_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "79465e52-1821-4b48-9157-dd1a32954857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['DATE', 'DailyAverageDewPointTemperature',\n",
      "       'DailyAverageDryBulbTemperature', 'DailyAverageRelativeHumidity',\n",
      "       'DailyAverageSeaLevelPressure', 'DailyAverageStationPressure',\n",
      "       'DailyAverageWetBulbTemperature', 'DailyAverageWindSpeed',\n",
      "       'DailyCoolingDegreeDays', 'DailyDepartureFromNormalAverageTemperature',\n",
      "       'DailyHeatingDegreeDays', 'DailyMaximumDryBulbTemperature',\n",
      "       'DailyMinimumDryBulbTemperature', 'DailyPeakWindDirection',\n",
      "       'DailyPeakWindSpeed', 'DailyPrecipitation', 'DailySnowDepth',\n",
      "       'DailySnowfall', 'DailySustainedWindDirection',\n",
      "       'DailySustainedWindSpeed', 'DailyWeather'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "daily_weather_df = pd.read_sql(\"SELECT * FROM daily_weather LIMIT 1;\", con=engine)\n",
    "print(daily_weather_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "47b8c378-a34e-4ef7-ae87-b03d1dbff84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['DATE', 'HourlyAltimeterSetting', 'HourlyDewPointTemperature',\n",
      "       'HourlyDryBulbTemperature', 'HourlyPrecipitation',\n",
      "       'HourlyPresentWeatherType', 'HourlyPressureChange',\n",
      "       'HourlyPressureTendency', 'HourlyRelativeHumidity',\n",
      "       'HourlySkyConditions', 'HourlySeaLevelPressure',\n",
      "       'HourlyStationPressure', 'HourlyVisibility', 'HourlyWetBulbTemperature',\n",
      "       'HourlyWindDirection', 'HourlyWindGustSpeed', 'HourlyWindSpeed'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "hourly_weather_df = pd.read_sql(\"SELECT * FROM hourly_weather LIMIT 1;\", con=engine)\n",
    "print(hourly_weather_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "675efdaa-df3a-447e-886f-18c375b8557f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['daily_weather', 'hourly_range', 'hourly_weather', 'taxi_trips', 'uber_trips']\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import inspect\n",
    "\n",
    "# 检查数据库中的表名\n",
    "inspector = inspect(engine)\n",
    "print(inspector.get_table_names())  # 确认是否有 'hourly_range'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "0e68a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframes_to_table(table_to_df_dict):\n",
    "    with engine.connect() as connection:\n",
    "        for table_name, dataframe in table_to_df_dict.items():\n",
    "            try:\n",
    "                dataframe.to_sql(table_name, con=connection, if_exists=\"replace\", index=False)\n",
    "                print(f\"Data written to table: {table_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to write to table {table_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "45d6c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_table_name_to_dataframe = {\n",
    "    \"taxi_trips\": taxi_data,\n",
    "    \"uber_trips\": uber_data,\n",
    "    \"hourly_weather\": hourly_weather_data,\n",
    "    \"daily_weather\": daily_weather_data,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "74004f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to table: taxi_trips\n",
      "Data written to table: uber_trips\n",
      "Data written to table: hourly_weather\n",
      "Data written to table: daily_weather\n"
     ]
    }
   ],
   "source": [
    "write_dataframes_to_table(map_table_name_to_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb6e33e",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "6a849e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to write the queries to file\n",
    "def write_query_to_file(query, outfile):\n",
    "    filepath = os.path.join(QUERY_DIRECTORY, outfile)\n",
    "    with open(filepath, \"w\") as f:\n",
    "        f.write(query)\n",
    "    print(f\"Query written to file: {filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee70a777",
   "metadata": {},
   "source": [
    "### Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "db871d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_1_FILENAME = \"Query 1: Popular taxi hour.sql\"\n",
    "\n",
    "QUERY_1 = \"\"\"\n",
    "SELECT strftime('%H', tpep_pickup_datetime) AS hour,\n",
    "       COUNT(*) AS ride_count\n",
    "FROM taxi_trips\n",
    "WHERE tpep_pickup_datetime BETWEEN '2020-01-01' AND '2024-08-31'\n",
    "GROUP BY hour\n",
    "ORDER BY ride_count DESC;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "c5275f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  hour  ride_count\n",
      "0   18        1560\n",
      "1   17        1497\n",
      "2   15        1457\n",
      "3   16        1410\n",
      "4   14        1395\n"
     ]
    }
   ],
   "source": [
    "# execute query either via pandas\n",
    "df_query_1 = pd.read_sql(QUERY_1, con=engine)\n",
    "print(df_query_1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "a2ef04df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query written to file: queries/Query 1: Popular taxi hour.sql\n"
     ]
    }
   ],
   "source": [
    "write_query_to_file(QUERY_1, QUERY_1_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e321fdda-ac6d-4e34-b54f-e1c2829dd97b",
   "metadata": {},
   "source": [
    "### Query 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "80fc02a0-6209-4fea-a1bb-6e90f0b42dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_2_FILENAME = \"Query 2: Popular uber day.sql\"\n",
    "\n",
    "QUERY_2 = \"\"\"\n",
    "SELECT strftime('%w', pickup_datetime) AS weekday,\n",
    "       COUNT(*) AS ride_count\n",
    "FROM uber_trips\n",
    "WHERE pickup_datetime BETWEEN '2020-01-01' AND '2024-08-31'\n",
    "GROUP BY weekday\n",
    "ORDER BY ride_count DESC;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "db93de9e-8031-46e6-8f35-54b40bde58e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  weekday  ride_count\n",
      "0       6        2509\n",
      "1       5        2352\n",
      "2       4        2114\n",
      "3       0        2027\n",
      "4       3        1995\n"
     ]
    }
   ],
   "source": [
    "# execute query either via sqlalchemy\n",
    "df_query_2 = pd.read_sql(QUERY_2, con=engine)\n",
    "print(df_query_2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "b06e2002-8e16-4477-b459-82bf1a39a0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query written to file: queries/Query 2: Popular uber day.sql\n"
     ]
    }
   ],
   "source": [
    "write_query_to_file(QUERY_2, QUERY_2_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80aa0db-3a43-43a5-9d2e-1e6a7bb7a77b",
   "metadata": {},
   "source": [
    "### Query 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "599e0155-2061-4792-a2d2-780ae50a3b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_3_FILENAME = \"Query 3: Trip distance.sql\"\n",
    "\n",
    "QUERY_3 = \"\"\"\n",
    "WITH combined_trips AS (\n",
    "    SELECT trip_distance\n",
    "    FROM taxi_trips\n",
    "    WHERE tpep_pickup_datetime BETWEEN '2024-01-01' AND '2024-01-31'\n",
    "    UNION ALL\n",
    "    SELECT trip_miles AS trip_distance\n",
    "    FROM uber_trips\n",
    "    WHERE pickup_datetime BETWEEN '2024-01-01' AND '2024-01-31'\n",
    "),\n",
    "sorted_trips AS (\n",
    "    SELECT trip_distance\n",
    "    FROM combined_trips\n",
    "    ORDER BY trip_distance\n",
    "),\n",
    "percentile_index AS (\n",
    "    SELECT CAST(COUNT(*) * 0.95 AS INTEGER) AS idx\n",
    "    FROM sorted_trips\n",
    ")\n",
    "SELECT trip_distance AS percentile_95\n",
    "FROM sorted_trips\n",
    "LIMIT 1 OFFSET (SELECT idx - 1 FROM percentile_index);\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "8b2d0893-e53a-428a-ba3b-34ea0e448d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   percentile_95\n",
      "0           16.1\n"
     ]
    }
   ],
   "source": [
    "# execute query either via sqlalchemy\n",
    "df_query_3 = pd.read_sql(QUERY_3, con=engine)\n",
    "print(df_query_3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "3befd498-b18d-4695-ac7f-cf91d49e221e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query written to file: queries/Query 3: Trip distance.sql\n"
     ]
    }
   ],
   "source": [
    "write_query_to_file(QUERY_3, QUERY_3_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b71db3-dd4c-41b5-a34c-4f51c1f9d76f",
   "metadata": {},
   "source": [
    "### Query 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "ab8f087d-5014-4d25-952c-416b8e1786ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_4_FILENAME = \"Query 4: Busiest days weather.sql\"\n",
    "\n",
    "QUERY_4 = \"\"\"\n",
    "WITH daily_rides AS (\n",
    "    SELECT strftime('%Y-%m-%d', pickup_datetime) AS ride_date,\n",
    "           COUNT(*) AS total_rides,\n",
    "           AVG(trip_distance) AS avg_distance\n",
    "    FROM (\n",
    "        SELECT tpep_pickup_datetime AS pickup_datetime, trip_distance\n",
    "        FROM taxi_trips\n",
    "        WHERE tpep_pickup_datetime BETWEEN '2023-01-01' AND '2023-12-31'\n",
    "        UNION ALL\n",
    "        SELECT pickup_datetime, trip_miles AS trip_distance\n",
    "        FROM uber_trips\n",
    "        WHERE pickup_datetime BETWEEN '2023-01-01' AND '2023-12-31'\n",
    "    ) AS all_rides\n",
    "    GROUP BY ride_date\n",
    ")\n",
    "SELECT d.ride_date, \n",
    "       d.total_rides, \n",
    "       d.avg_distance, \n",
    "       w.DailyPrecipitation AS avg_precipitation, \n",
    "       w.DailyAverageWindSpeed AS avg_wind_speed\n",
    "FROM daily_rides d\n",
    "LEFT JOIN daily_weather w ON d.ride_date = w.DATE\n",
    "ORDER BY d.total_rides DESC\n",
    "LIMIT 10;\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "ef98da5b-db99-400a-a870-aff3081f08b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ride_date  total_rides  avg_distance avg_precipitation avg_wind_speed\n",
      "0  2023-11-09           37      3.009459              None           None\n",
      "1  2023-07-28           35      4.087429              None           None\n",
      "2  2023-12-15           35      3.393429              None           None\n",
      "3  2023-04-30           34      5.202647              None           None\n",
      "4  2023-05-05           34      3.377647              None           None\n"
     ]
    }
   ],
   "source": [
    "# execute query either via sqlalchemy\n",
    "df_query_4 = pd.read_sql(QUERY_4, con=engine)\n",
    "print(df_query_4.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "16b4abd3-5993-4987-9682-0cec1e3a16dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query written to file: queries/Query 4: Busiest days weather.sql\n"
     ]
    }
   ],
   "source": [
    "write_query_to_file(QUERY_4, QUERY_4_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fdc435-2efd-4861-8933-a13f37b01fba",
   "metadata": {},
   "source": [
    "### Query 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "eee98886-068e-42fe-b0f2-f3d86ee6b2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_5_FILENAME = \"Query 5: Rides_on_snow_days.sql\"\n",
    "\n",
    "QUERY_5 = \"\"\"\n",
    "WITH daily_trip_counts AS (\n",
    "    SELECT strftime('%Y-%m-%d', pickup_datetime) AS ride_date,\n",
    "           COUNT(*) AS total_rides\n",
    "    FROM (\n",
    "        SELECT tpep_pickup_datetime AS pickup_datetime\n",
    "        FROM taxi_trips\n",
    "        WHERE tpep_pickup_datetime BETWEEN '2020-01-01' AND '2024-08-31'\n",
    "        UNION ALL\n",
    "        SELECT pickup_datetime\n",
    "        FROM uber_trips\n",
    "        WHERE pickup_datetime BETWEEN '2020-01-01' AND '2024-08-31'\n",
    "    ) AS all_trips\n",
    "    GROUP BY ride_date\n",
    ")\n",
    "SELECT w.DATE AS ride_date, \n",
    "       w.DailySnowfall AS total_snowfall, \n",
    "       COALESCE(d.total_rides, 0) AS total_rides\n",
    "FROM daily_weather w\n",
    "LEFT JOIN daily_trip_counts d ON w.DATE = d.ride_date\n",
    "WHERE w.DATE BETWEEN '2020-01-01' AND '2024-08-31'\n",
    "ORDER BY w.DailySnowfall DESC\n",
    "LIMIT 10;\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "273b65bb-2b0c-4d6a-bf9c-8a22e1360657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ride_date total_snowfall  total_rides\n",
      "0  2020-01-08T23:59:00              T            0\n",
      "1  2020-01-16T23:59:00              T            0\n",
      "2  2020-02-02T23:59:00              T            0\n",
      "3  2020-02-07T23:59:00              T            0\n",
      "4  2020-03-23T23:59:00              T            0\n"
     ]
    }
   ],
   "source": [
    "df_query_5 = pd.read_sql(QUERY_5, con=engine)\n",
    "print(df_query_5.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "0bbdc0ee-53b0-46ab-b91c-5b97836692b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query written to file: queries/Query 5: Rides_on_snow_days.sql\n"
     ]
    }
   ],
   "source": [
    "write_query_to_file(QUERY_5, QUERY_5_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6f177d-8d79-41e9-b048-e1178ffd2f8c",
   "metadata": {},
   "source": [
    "### Query 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "3501123e-3ea4-4c65-9f2a-a3e76ba0fc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_6_FILENAME = \"Query 6: Ophelia_weather_rides.sql\"\n",
    "\n",
    "QUERY_6 = \"\"\"\n",
    "WITH hourly_rides AS (\n",
    "    SELECT strftime('%Y-%m-%d %H:00:00', pickup_datetime) AS hour,\n",
    "           COUNT(*) AS total_rides\n",
    "    FROM (\n",
    "        SELECT tpep_pickup_datetime AS pickup_datetime\n",
    "        FROM taxi_trips\n",
    "        WHERE tpep_pickup_datetime BETWEEN '2023-09-25' AND '2023-10-03'\n",
    "        UNION ALL\n",
    "        SELECT pickup_datetime\n",
    "        FROM uber_trips\n",
    "        WHERE pickup_datetime BETWEEN '2023-09-25' AND '2023-10-03'\n",
    "    ) AS all_trips\n",
    "    GROUP BY hour\n",
    "),\n",
    "hourly_data AS (\n",
    "    SELECT strftime('%Y-%m-%d %H:00:00', DATE) AS hour,\n",
    "           SUM(HourlyPrecipitation) AS total_precipitation,\n",
    "           AVG(HourlyWindSpeed) AS avg_wind_speed\n",
    "    FROM hourly_weather\n",
    "    WHERE DATE BETWEEN '2023-09-25 00:00:00' AND '2023-10-03 23:59:59'\n",
    "    GROUP BY hour\n",
    ")\n",
    "SELECT hr.hour,\n",
    "       COALESCE(r.total_rides, 0) AS total_rides,\n",
    "       COALESCE(h.total_precipitation, 0) AS total_precipitation,\n",
    "       COALESCE(h.avg_wind_speed, 0) AS avg_wind_speed\n",
    "FROM hourly_range hr\n",
    "LEFT JOIN hourly_rides r ON hr.hour = r.hour\n",
    "LEFT JOIN hourly_data h ON hr.hour = h.hour\n",
    "ORDER BY hr.hour ASC;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "dc08f4a2-2249-4630-b217-bc7fc5979003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  hour  total_rides  total_precipitation  avg_wind_speed\n",
      "0  2023-09-25 00:00:00            0                 0.07        8.333333\n",
      "1  2023-09-25 01:00:00            0                 0.12        7.000000\n",
      "2  2023-09-25 02:00:00            0                 0.14        7.000000\n",
      "3  2023-09-25 03:00:00            0                 0.04        7.000000\n",
      "4  2023-09-25 04:00:00            0                 0.01        6.000000\n"
     ]
    }
   ],
   "source": [
    "# execute query either via sqlalchemy\n",
    "df_query_6 = pd.read_sql(QUERY_6, con=engine)\n",
    "print(df_query_6.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "5769fad4-1800-469f-b01d-cd37151ddc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query written to file: queries/Query 6: Ophelia_weather_rides.sql\n"
     ]
    }
   ],
   "source": [
    "write_query_to_file(QUERY_6, QUERY_6_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ced42",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9eef42",
   "metadata": {},
   "source": [
    "### Visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more descriptive name for your function\n",
    "def plot_visual_1(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ced2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_1():\n",
    "    # Query SQL database for the data needed.\n",
    "    # You can put the data queried into a pandas dataframe, if you wish\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_1()\n",
    "plot_visual_1(some_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
